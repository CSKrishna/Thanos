{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    30     0        50     1/111807       0% 1.407020               31.2500             \n",
      "    65     0       100     1/111807       0% 1.339240               31.2500             \n",
      "   101     0       150     1/111807       0% 1.395856               34.3750             \n",
      "   129     0       200     1/111807       0% 1.238722               40.6250             \n",
      "   162     0       250     1/111807       0% 1.149573               40.6250             \n",
      "   193     0       300     1/111807       0% 1.327331               50.0000             \n",
      "   225     0       350     1/111807       0% 1.131130               40.6250             \n",
      "   255     0       400     1/111807       0% 1.399145               28.1250             \n",
      "   288     0       450     1/111807       0% 1.280921               46.8750             \n",
      "   538     0       500     1/111807       0% 1.238437 1.409585      40.6250      40.0920\n",
      "   538     0       500     1/111807       0% 1.238437               40.6250             \n",
      "   575     0       550     1/111807       0% 1.139691               56.2500             \n",
      "   612     0       600     1/111807       0% 1.303789               43.7500             \n",
      "   646     0       650     1/111807       0% 1.221521               50.0000             \n",
      "   679     0       700     1/111807       0% 1.410422               31.2500             \n",
      "   712     0       750     1/111807       0% 1.081201               56.2500             \n",
      "   746     0       800     1/111807       0% 1.410692               46.8750             \n",
      "   781     0       850     1/111807       0% 1.083085               46.8750             \n",
      "   819     0       900     1/111807       0% 1.141076               43.7500             \n",
      "   865     0       950     1/111807       0% 1.239955               40.6250             \n",
      "  1121     0      1000     1/111807       0% 1.116330 1.206204      46.8750      45.8479\n",
      "  1121     0      1000     1/111807       0% 1.116330               46.8750             \n",
      "  1165     0      1050     1/111807       0% 0.999615               50.0000             \n",
      "  1207     0      1100     1/111807       0% 1.101904               43.7500             \n",
      "  1247     0      1150     1/111807       0% 1.172390               40.6250             \n",
      "  1290     0      1200     1/111807       0% 1.303865               28.1250             \n",
      "  1338     0      1250     1/111807       0% 1.120806               65.6250             \n",
      "  1386     0      1300     1/111807       0% 1.224522               43.7500             \n",
      "  1428     0      1350     1/111807       0% 0.961426               75.0000             \n",
      "  1473     0      1400     1/111807       0% 1.215713               43.7500             \n",
      "  1517     0      1450     1/111807       0% 1.141319               37.5000             \n",
      "  1763     0      1500     1/111807       0% 1.012702 1.175197      62.5000      47.4552\n",
      "  1763     0      1500     1/111807       0% 1.012702               62.5000             \n",
      "  1814     0      1550     1/111807       0% 0.978527               53.1250             \n",
      "  1863     0      1600     1/111807       0% 1.092243               56.2500             \n",
      "  1914     0      1650     1/111807       0% 1.036125               53.1250             \n",
      "  1964     0      1700     1/111807       0% 1.141967               37.5000             \n",
      "  2014     0      1750     1/111807       0% 1.121957               50.0000             \n",
      "  2089     0      1800     1/111807       0% 1.237431               43.7500             \n",
      "  2152     0      1850     1/111807       0% 0.944053               50.0000             \n",
      "  2218     0      1900     1/111807       0% 1.371615               43.7500             \n",
      "  2280     0      1950     1/111807       0% 1.101229               43.7500             \n",
      "  2622     0      2000     1/111807       0% 1.271021 1.071239      46.8750      50.9856\n",
      "  2622     0      2000     1/111807       0% 1.271021               46.8750             \n",
      "  2697     0      2050     1/111807       0% 0.948553               62.5000             \n",
      "  2775     0      2100     1/111807       0% 0.964632               65.6250             \n",
      "  2848     0      2150     1/111807       0% 0.862733               50.0000             \n",
      "  2924     0      2200     1/111807       0% 0.855951               59.3750             \n",
      "  3005     0      2250     1/111807       0% 0.935418               46.8750             \n",
      "  3094     0      2300     1/111807       0% 1.250266               37.5000             \n",
      "  3189     0      2350     1/111807       0% 1.280272               34.3750             \n",
      "  3272     0      2400     1/111807       0% 0.998691               46.8750             \n",
      "  3352     0      2450     1/111807       0% 1.015235               62.5000             \n"
     ]
    }
   ],
   "source": [
    "% run train_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    27     0        50     1/111807       0% 1.402930               31.2500             \n",
      "    52     0       100     1/111807       0% 1.340614               28.1250             \n",
      "    80     0       150     1/111807       0% 1.392423               34.3750             \n",
      "   107     0       200     1/111807       0% 1.289314               53.1250             \n",
      "   139     0       250     1/111807       0% 1.082345               56.2500             \n",
      "   168     0       300     1/111807       0% 1.361138               40.6250             \n",
      "   199     0       350     1/111807       0% 1.136634               43.7500             \n",
      "   228     0       400     1/111807       0% 1.392245               37.5000             \n",
      "   259     0       450     1/111807       0% 1.182737               50.0000             \n",
      "   479     0       500     1/111807       0% 1.259564 1.361749      40.6250      42.5716\n",
      "   479     0       500     1/111807       0% 1.259564               40.6250             \n",
      "   514     0       550     1/111807       0% 1.083432               56.2500             \n",
      "   551     0       600     1/111807       0% 1.257980               53.1250             \n",
      "   584     0       650     1/111807       0% 1.231517               53.1250             \n",
      "   619     0       700     1/111807       0% 1.364237               37.5000             \n",
      "   653     0       750     1/111807       0% 1.087375               50.0000             \n",
      "   687     0       800     1/111807       0% 1.320367               46.8750             \n",
      "   722     0       850     1/111807       0% 0.992376               59.3750             \n",
      "   759     0       900     1/111807       0% 1.066025               43.7500             \n",
      "   799     0       950     1/111807       0% 1.130028               40.6250             \n",
      "  1041     0      1000     1/111807       0% 1.038568 1.130706      59.3750      48.0390\n",
      "  1041     0      1000     1/111807       0% 1.038568               59.3750             \n",
      "  1081     0      1050     1/111807       0% 1.011581               50.0000             \n",
      "  1121     0      1100     1/111807       0% 1.052504               50.0000             \n",
      "  1160     0      1150     1/111807       0% 1.025433               43.7500             \n",
      "  1201     0      1200     1/111807       0% 1.275686               28.1250             \n",
      "  1247     0      1250     1/111807       0% 1.051812               68.7500             \n",
      "  1294     0      1300     1/111807       0% 1.076629               53.1250             \n",
      "  1336     0      1350     1/111807       0% 0.870832               75.0000             \n",
      "  1381     0      1400     1/111807       0% 1.103360               40.6250             \n",
      "  1427     0      1450     1/111807       0% 1.010878               37.5000             \n",
      "  1675     0      1500     1/111807       0% 0.925707 1.037333      56.2500      53.1218\n",
      "  1675     0      1500     1/111807       0% 0.925707               56.2500             \n",
      "  1724     0      1550     1/111807       0% 0.848830               68.7500             \n",
      "  1772     0      1600     1/111807       0% 0.884744               59.3750             \n",
      "  1822     0      1650     1/111807       0% 0.956890               59.3750             \n",
      "  1872     0      1700     1/111807       0% 1.175298               50.0000             \n",
      "  1921     0      1750     1/111807       0% 1.104239               43.7500             \n",
      "  1974     0      1800     1/111807       0% 1.182299               40.6250             \n",
      "  2027     0      1850     1/111807       0% 0.911472               65.6250             \n",
      "  2082     0      1900     1/111807       0% 1.149234               53.1250             \n",
      "  2133     0      1950     1/111807       0% 0.876593               56.2500             \n",
      "  2407     0      2000     1/111807       0% 1.052570 0.991518      50.0000      55.7799\n",
      "  2407     0      2000     1/111807       0% 1.052570               50.0000             \n",
      "  2468     0      2050     1/111807       0% 0.913440               53.1250             \n",
      "  2533     0      2100     1/111807       0% 0.864295               75.0000             \n",
      "  2594     0      2150     1/111807       0% 0.689227               68.7500             \n",
      "  2657     0      2200     1/111807       0% 0.754152               68.7500             \n",
      "  2723     0      2250     1/111807       0% 0.775988               62.5000             \n",
      "  2795     0      2300     1/111807       0% 0.948611               62.5000             \n",
      "  2868     0      2350     1/111807       0% 1.292771               59.3750             \n",
      "  2942     0      2400     1/111807       0% 0.964277               53.1250             \n",
      "  3019     0      2450     1/111807       0% 0.937560               59.3750             \n",
      "  3369     0      2500     1/111807       0% 0.990847 0.954090      59.3750      57.5726\n",
      "  3369     0      2500     1/111807       0% 0.990847               59.3750             \n",
      "  3461     0      2550     1/111807       0% 0.870881               59.3750             \n",
      "  3552     0      2600     1/111807       0% 1.172669               40.6250             \n",
      "  3648     0      2650     1/111807       0% 0.749004               78.1250             \n",
      "  3753     0      2700     1/111807       0% 1.200011               50.0000             \n",
      "  3861     0      2750     1/111807       0% 1.042012               37.5000             \n",
      "  3967     0      2800     1/111807       0% 0.917059               62.5000             \n",
      "  4076     0      2850     1/111807       0% 1.250175               40.6250             \n",
      "  4194     0      2900     1/111807       0% 0.931312               53.1250             \n",
      "  4319     0      2950     1/111807       0% 0.807627               68.7500             \n",
      "  4836     0      3000     1/111807       0% 1.198742 0.926307      46.8750      58.9051\n",
      "  4836     0      3000     1/111807       0% 1.198742               46.8750             \n",
      "  4984     0      3050     1/111807       0% 0.806059               68.7500             \n",
      "  5136     0      3100     1/111807       0% 1.034940               56.2500             \n",
      "  5295     0      3150     1/111807       0% 1.001830               50.0000             \n",
      "  5491     0      3200     1/111807       0% 0.839689               62.5000             \n",
      "  5674     0      3250     1/111807       0% 0.864159               59.3750             \n",
      "  5889     0      3300     1/111807       0% 0.994506               46.8750             \n",
      "  6119     0      3350     1/111807       0% 0.756037               65.6250             \n",
      "  6380     0      3400     1/111807       0% 0.924080               53.1250             \n",
      "  6655     0      3450     1/111807       0% 1.083010               50.0000             \n",
      "  7510     1      3500     1/111807       0% 1.097370 0.982142      43.7500      55.5601\n",
      "  7510     1      3500     1/111807       0% 1.097370               43.7500             \n",
      "  7566     1      3550     1/111807       0% 1.020542               50.0000             \n",
      "  7626     1      3600     1/111807       0% 0.826689               65.6250             \n",
      "  7685     1      3650     1/111807       0% 0.952179               56.2500             \n",
      "  7743     1      3700     1/111807       0% 1.303928               34.3750             \n",
      "  7816     1      3750     1/111807       0% 1.112529               53.1250             \n",
      "  7888     1      3800     1/111807       0% 1.036116               46.8750             \n",
      "  7960     1      3850     1/111807       0% 1.073557               62.5000             \n",
      "  8030     1      3900     1/111807       0% 0.804288               68.7500             \n",
      "  8101     1      3950     1/111807       0% 0.931128               62.5000             \n",
      "  8717     1      4000     1/111807       0% 0.756999 0.902087      59.3750      59.8599\n",
      "  8717     1      4000     1/111807       0% 0.756999               59.3750             \n",
      "  8798     1      4050     1/111807       0% 0.743403               68.7500             \n",
      "  8880     1      4100     1/111807       0% 0.873650               65.6250             \n",
      "  8959     1      4150     1/111807       0% 0.812451               65.6250             \n",
      "  9038     1      4200     1/111807       0% 0.768067               62.5000             \n",
      "  9114     1      4250     1/111807       0% 1.132144               53.1250             \n",
      "  9194     1      4300     1/111807       0% 0.942054               56.2500             \n",
      "  9277     1      4350     1/111807       0% 0.866741               71.8750             \n",
      "  9368     1      4400     1/111807       0% 0.913784               53.1250             \n",
      "  9460     1      4450     1/111807       0% 0.866732               50.0000             \n",
      " 10100     1      4500     1/111807       0% 0.850782 0.921348      56.2500      58.2870\n",
      " 10100     1      4500     1/111807       0% 0.850782               56.2500             \n",
      " 10191     1      4550     1/111807       0% 0.682591               68.7500             \n",
      " 10283     1      4600     1/111807       0% 0.903927               59.3750             \n",
      " 10374     1      4650     1/111807       0% 0.793831               62.5000             \n",
      " 10473     1      4700     1/111807       0% 0.906401               59.3750             \n",
      " 10583     1      4750     1/111807       0% 0.938877               75.0000             \n",
      " 10693     1      4800     1/111807       0% 0.770831               78.1250             \n",
      " 10796     1      4850     1/111807       0% 1.055426               50.0000             \n",
      " 10902     1      4900     1/111807       0% 0.839529               68.7500             \n",
      " 11007     1      4950     1/111807       0% 1.104215               43.7500             \n",
      " 11662     1      5000     1/111807       0% 0.632863 0.889445      78.1250      60.2102\n",
      " 11662     1      5000     1/111807       0% 0.632863               78.1250             \n",
      " 11779     1      5050     1/111807       0% 0.797194               75.0000             \n",
      " 11897     1      5100     1/111807       0% 0.782263               59.3750             \n",
      " 12016     1      5150     1/111807       0% 0.863086               62.5000             \n",
      " 12135     1      5200     1/111807       0% 0.628876               75.0000             \n",
      " 12252     1      5250     1/111807       0% 0.766722               71.8750             \n",
      " 12380     1      5300     1/111807       0% 0.939363               53.1250             \n",
      " 12510     1      5350     1/111807       0% 0.925163               59.3750             \n",
      " 12640     1      5400     1/111807       0% 0.826870               68.7500             \n",
      " 12769     1      5450     1/111807       0% 0.817654               68.7500             \n",
      " 13437     1      5500     1/111807       0% 0.921266 0.886685      65.6250      60.0934\n",
      " 13437     1      5500     1/111807       0% 0.921266               65.6250             \n",
      " 13580     1      5550     1/111807       0% 0.714516               71.8750             \n",
      " 13725     1      5600     1/111807       0% 0.875904               65.6250             \n",
      " 13867     1      5650     1/111807       0% 0.863275               56.2500             \n",
      " 14013     1      5700     1/111807       0% 1.068630               53.1250             \n",
      " 14165     1      5750     1/111807       0% 0.692098               71.8750             \n",
      " 14325     1      5800     1/111807       0% 0.836993               62.5000             \n",
      " 14484     1      5850     1/111807       0% 1.026449               53.1250             \n",
      " 14645     1      5900     1/111807       0% 0.925387               62.5000             \n",
      " 14811     1      5950     1/111807       0% 0.831863               65.6250             \n",
      " 15509     1      6000     1/111807       0% 0.676409 0.861191      78.1250      61.6938\n",
      " 15509     1      6000     1/111807       0% 0.676409               78.1250             \n",
      " 15685     1      6050     1/111807       0% 0.842003               62.5000             \n",
      " 15862     1      6100     1/111807       0% 0.715231               75.0000             \n",
      " 16045     1      6150     1/111807       0% 0.672605               62.5000             \n",
      " 16233     1      6200     1/111807       0% 0.696738               75.0000             \n",
      " 16431     1      6250     1/111807       0% 0.888058               53.1250             \n",
      " 16627     1      6300     1/111807       0% 0.941388               59.3750             \n",
      " 16821     1      6350     1/111807       0% 0.801012               59.3750             \n",
      " 17023     1      6400     1/111807       0% 0.753502               62.5000             \n",
      " 17233     1      6450     1/111807       0% 0.850005               59.3750             \n",
      " 17988     1      6500     1/111807       0% 1.040721 0.874235      46.8750      61.0413\n",
      " 17988     1      6500     1/111807       0% 1.040721               46.8750             \n",
      " 18212     1      6550     1/111807       0% 0.742734               62.5000             \n",
      " 18447     1      6600     1/111807       0% 0.907924               46.8750             \n",
      " 18679     1      6650     1/111807       0% 0.882991               53.1250             \n",
      " 18922     1      6700     1/111807       0% 0.862808               53.1250             \n",
      " 19172     1      6750     1/111807       0% 1.066804               43.7500             \n",
      " 19429     1      6800     1/111807       0% 0.935333               65.6250             \n",
      " 19693     1      6850     1/111807       0% 0.876912               59.3750             \n",
      " 19981     1      6900     1/111807       0% 1.072599               43.7500             \n",
      " 20263     1      6950     1/111807       0% 0.897134               53.1250             \n",
      " 21046     2      7000     1/111807       0% 0.915165 0.916932      62.5000      57.1949\n",
      " 21046     2      7000     1/111807       0% 0.915165               62.5000             \n",
      " 21103     2      7050     1/111807       0% 0.796456               56.2500             \n",
      " 21161     2      7100     1/111807       0% 1.074296               40.6250             \n",
      " 21220     2      7150     1/111807       0% 0.933277               62.5000             \n",
      " 21282     2      7200     1/111807       0% 0.827835               68.7500             \n",
      " 21351     2      7250     1/111807       0% 0.752215               68.7500             \n",
      " 21422     2      7300     1/111807       0% 0.842124               62.5000             \n",
      " 21490     2      7350     1/111807       0% 0.921328               56.2500             \n",
      " 21558     2      7400     1/111807       0% 0.770475               62.5000             \n",
      " 21626     2      7450     1/111807       0% 0.947397               56.2500             \n",
      " 22239     2      7500     1/111807       0% 0.808981 0.874168      56.2500      61.1718\n",
      " 22239     2      7500     1/111807       0% 0.808981               56.2500             \n",
      " 22320     2      7550     1/111807       0% 0.903291               59.3750             \n",
      " 22400     2      7600     1/111807       0% 1.148321               56.2500             \n",
      " 22479     2      7650     1/111807       0% 0.920101               50.0000             \n",
      " 22557     2      7700     1/111807       0% 0.681420               71.8750             \n",
      " 22632     2      7750     1/111807       0% 0.903178               62.5000             \n",
      " 22712     2      7800     1/111807       0% 0.999256               56.2500             \n",
      " 22800     2      7850     1/111807       0% 0.860022               56.2500             \n",
      " 22892     2      7900     1/111807       0% 0.626305               81.2500             \n",
      " 22986     2      7950     1/111807       0% 0.768766               59.3750             \n",
      " 23635     2      8000     1/111807       0% 0.583823 0.859037      68.7500      61.7350\n",
      " 23635     2      8000     1/111807       0% 0.583823               68.7500             \n",
      " 23733     2      8050     1/111807       0% 0.818381               65.6250             \n",
      " 23832     2      8100     1/111807       0% 0.712975               75.0000             \n",
      " 23929     2      8150     1/111807       0% 0.637573               81.2500             \n",
      " 24040     2      8200     1/111807       0% 0.841865               56.2500             \n",
      " 24159     2      8250     1/111807       0% 0.888300               50.0000             \n",
      " 24277     2      8300     1/111807       0% 0.769349               68.7500             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24389     2      8350     1/111807       0% 0.917192               59.3750             \n",
      " 24504     2      8400     1/111807       0% 0.689950               65.6250             \n",
      " 24617     2      8450     1/111807       0% 0.769305               65.6250             \n",
      " 25326     2      8500     1/111807       0% 0.848643 0.869410      50.0000      61.7968\n",
      " 25326     2      8500     1/111807       0% 0.848643               50.0000             \n",
      " 25456     2      8550     1/111807       0% 0.652508               71.8750             \n",
      " 25585     2      8600     1/111807       0% 0.754110               59.3750             \n",
      " 25716     2      8650     1/111807       0% 0.788130               75.0000             \n",
      " 25848     2      8700     1/111807       0% 0.688049               71.8750             \n",
      " 25977     2      8750     1/111807       0% 0.922326               75.0000             \n",
      " 26122     2      8800     1/111807       0% 0.706361               75.0000             \n",
      " 26267     2      8850     1/111807       0% 1.117441               50.0000             \n",
      " 26414     2      8900     1/111807       0% 0.900611               56.2500             \n",
      " 26559     2      8950     1/111807       0% 1.060549               59.3750             \n",
      " 27291     2      9000     1/111807       0% 1.084217 0.907410      43.7500      58.6029\n",
      " 27291     2      9000     1/111807       0% 1.084217               43.7500             \n",
      " 27456     2      9050     1/111807       0% 0.782607               56.2500             \n",
      " 27622     2      9100     1/111807       0% 0.887586               68.7500             \n",
      " 27786     2      9150     1/111807       0% 0.975550               56.2500             \n",
      " 27953     2      9200     1/111807       0% 1.003588               68.7500             \n",
      " 28125     2      9250     1/111807       0% 0.718058               65.6250             \n",
      " 28308     2      9300     1/111807       0% 0.520080               81.2500             \n",
      " 28489     2      9350     1/111807       0% 0.975685               59.3750             \n",
      " 28670     2      9400     1/111807       0% 0.674469               71.8750             \n",
      " 28862     2      9450     1/111807       0% 0.679822               78.1250             \n",
      " 29641     2      9500     1/111807       0% 0.621079 0.849448      75.0000      61.8861\n",
      " 29641     2      9500     1/111807       0% 0.621079               75.0000             \n",
      " 29836     2      9550     1/111807       0% 0.755975               59.3750             \n",
      " 30034     2      9600     1/111807       0% 0.724383               68.7500             \n",
      " 30238     2      9650     1/111807       0% 0.723373               59.3750             \n",
      " 30445     2      9700     1/111807       0% 0.996190               46.8750             \n",
      " 30658     2      9750     1/111807       0% 0.769838               65.6250             \n",
      " 30876     2      9800     1/111807       0% 0.979632               50.0000             \n",
      " 31093     2      9850     1/111807       0% 0.603470               71.8750             \n",
      " 31318     2      9900     1/111807       0% 0.743351               68.7500             \n",
      " 31548     2      9950     1/111807       0% 0.671208               71.8750             \n"
     ]
    }
   ],
   "source": [
    "% run train_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    34     0        50     1/111807       0% 1.402873               31.2500             \n",
      "    67     0       100     1/111807       0% 1.306998               43.7500             \n",
      "   105     0       150     1/111807       0% 1.348002               21.8750             \n",
      "   141     0       200     1/111807       0% 1.153292               56.2500             \n",
      "   184     0       250     1/111807       0% 0.941104               62.5000             \n",
      "   224     0       300     1/111807       0% 1.190249               43.7500             \n",
      "   269     0       350     1/111807       0% 1.073822               53.1250             \n",
      "   311     0       400     1/111807       0% 1.376545               43.7500             \n",
      "   355     0       450     1/111807       0% 1.140655               56.2500             \n",
      "   618     0       500     1/111807       0% 1.184331 1.292924      37.5000      41.0330\n",
      "   618     0       500     1/111807       0% 1.184331               37.5000             \n",
      "   669     0       550     1/111807       0% 1.038299               56.2500             \n",
      "   722     0       600     1/111807       0% 1.166740               40.6250             \n",
      "   770     0       650     1/111807       0% 1.053720               53.1250             \n",
      "   815     0       700     1/111807       0% 1.151801               50.0000             \n",
      "   862     0       750     1/111807       0% 0.946236               50.0000             \n",
      "   910     0       800     1/111807       0% 1.095934               56.2500             \n",
      "   959     0       850     1/111807       0% 0.872774               71.8750             \n",
      "  1010     0       900     1/111807       0% 1.018365               56.2500             \n",
      "  1065     0       950     1/111807       0% 0.916152               65.6250             \n",
      "  1380     0      1000     1/111807       0% 0.823018 1.023320      65.6250      54.4406\n",
      "  1380     0      1000     1/111807       0% 0.823018               65.6250             \n",
      "  1438     0      1050     1/111807       0% 0.975312               56.2500             \n",
      "  1498     0      1100     1/111807       0% 0.881480               68.7500             \n",
      "  1550     0      1150     1/111807       0% 0.897086               53.1250             \n",
      "  1599     0      1200     1/111807       0% 1.253154               34.3750             \n",
      "  1655     0      1250     1/111807       0% 0.902158               71.8750             \n",
      "  1712     0      1300     1/111807       0% 1.115405               37.5000             \n",
      "  1762     0      1350     1/111807       0% 0.947062               53.1250             \n",
      "  1817     0      1400     1/111807       0% 0.975617               56.2500             \n",
      "  1869     0      1450     1/111807       0% 0.813721               65.6250             \n",
      "  2144     0      1500     1/111807       0% 0.894181 0.977885      59.3750      56.2745\n",
      "  2144     0      1500     1/111807       0% 0.894181               59.3750             \n",
      "  2203     0      1550     1/111807       0% 0.844634               53.1250             \n",
      "  2261     0      1600     1/111807       0% 0.796985               65.6250             \n",
      "  2322     0      1650     1/111807       0% 0.853169               56.2500             \n",
      "  2382     0      1700     1/111807       0% 0.941012               56.2500             \n",
      "  2441     0      1750     1/111807       0% 0.996583               56.2500             \n",
      "  2506     0      1800     1/111807       0% 1.271827               34.3750             \n",
      "  2573     0      1850     1/111807       0% 0.785549               68.7500             \n",
      "  2647     0      1900     1/111807       0% 1.026439               59.3750             \n",
      "  2711     0      1950     1/111807       0% 0.840512               65.6250             \n",
      "  3039     0      2000     1/111807       0% 0.982225 0.916580      59.3750      58.8571\n",
      "  3039     0      2000     1/111807       0% 0.982225               59.3750             \n",
      "  3152     0      2050     1/111807       0% 0.928158               56.2500             \n",
      "  3251     0      2100     1/111807       0% 0.767474               68.7500             \n",
      "  3329     0      2150     1/111807       0% 0.655703               75.0000             \n",
      "  3407     0      2200     1/111807       0% 0.591537               78.1250             \n",
      "  3491     0      2250     1/111807       0% 0.776174               62.5000             \n",
      "  3583     0      2300     1/111807       0% 0.942478               56.2500             \n",
      "  3671     0      2350     1/111807       0% 1.299965               40.6250             \n",
      "  3761     0      2400     1/111807       0% 0.865413               59.3750             \n",
      "  3857     0      2450     1/111807       0% 0.979500               65.6250             \n",
      "  4239     0      2500     1/111807       0% 0.924010 0.895417      59.3750      59.9423\n",
      "  4239     0      2500     1/111807       0% 0.924010               59.3750             \n",
      "  4350     0      2550     1/111807       0% 0.782090               68.7500             \n",
      "  4462     0      2600     1/111807       0% 0.951138               53.1250             \n",
      "  4583     0      2650     1/111807       0% 0.739983               71.8750             \n",
      "  4704     0      2700     1/111807       0% 1.086559               50.0000             \n",
      "  4830     0      2750     1/111807       0% 0.797582               68.7500             \n",
      "  4959     0      2800     1/111807       0% 0.961802               59.3750             \n",
      "  5090     0      2850     1/111807       0% 1.021245               59.3750             \n",
      "  5229     0      2900     1/111807       0% 0.888557               62.5000             \n",
      "  5377     0      2950     1/111807       0% 0.852031               59.3750             \n",
      "  5903     0      3000     1/111807       0% 1.255761 0.880378      37.5000      60.5673\n",
      "  5903     0      3000     1/111807       0% 1.255761               37.5000             \n",
      "  6076     0      3050     1/111807       0% 0.845207               65.6250             \n",
      "  6262     0      3100     1/111807       0% 0.934020               62.5000             \n",
      "  6462     0      3150     1/111807       0% 0.993275               53.1250             \n",
      "  6675     0      3200     1/111807       0% 0.830894               71.8750             \n",
      "  6892     0      3250     1/111807       0% 0.843161               62.5000             \n",
      "  7142     0      3300     1/111807       0% 0.925512               56.2500             \n",
      "  7409     0      3350     1/111807       0% 0.727738               68.7500             \n",
      "  7717     0      3400     1/111807       0% 0.931926               68.7500             \n",
      "  8031     0      3450     1/111807       0% 0.967737               56.2500             \n",
      "  8930     1      3500     1/111807       0% 1.267528 0.881184      43.7500      60.6223\n",
      "  8930     1      3500     1/111807       0% 1.267528               43.7500             \n",
      "  8986     1      3550     1/111807       0% 0.954083               56.2500             \n",
      "  9049     1      3600     1/111807       0% 0.742288               75.0000             \n",
      "  9109     1      3650     1/111807       0% 0.994578               56.2500             \n",
      "  9169     1      3700     1/111807       0% 1.319553               43.7500             \n",
      "  9243     1      3750     1/111807       0% 1.086050               43.7500             \n",
      "  9317     1      3800     1/111807       0% 1.061279               46.8750             \n",
      "  9390     1      3850     1/111807       0% 1.010765               56.2500             \n",
      "  9461     1      3900     1/111807       0% 0.955104               65.6250             \n",
      "  9533     1      3950     1/111807       0% 0.932662               62.5000             \n",
      " 10149     1      4000     1/111807       0% 0.693972 0.878271      71.8750      60.7459\n",
      " 10149     1      4000     1/111807       0% 0.693972               71.8750             \n",
      " 10230     1      4050     1/111807       0% 0.619390               84.3750             \n",
      " 10314     1      4100     1/111807       0% 0.750925               81.2500             \n",
      " 10394     1      4150     1/111807       0% 0.877347               62.5000             \n",
      " 10474     1      4200     1/111807       0% 0.740288               68.7500             \n",
      " 10550     1      4250     1/111807       0% 0.961429               56.2500             \n",
      " 10631     1      4300     1/111807       0% 1.100608               50.0000             \n",
      " 10718     1      4350     1/111807       0% 0.829260               56.2500             \n",
      " 10814     1      4400     1/111807       0% 0.801501               65.6250             \n",
      " 10912     1      4450     1/111807       0% 0.876806               65.6250             \n",
      " 11553     1      4500     1/111807       0% 0.774808 0.886561      65.6250      61.2817\n",
      " 11553     1      4500     1/111807       0% 0.774808               65.6250             \n",
      " 11649     1      4550     1/111807       0% 0.704646               65.6250             \n",
      " 11745     1      4600     1/111807       0% 0.922435               56.2500             \n",
      " 11838     1      4650     1/111807       0% 0.931410               59.3750             \n",
      " 11940     1      4700     1/111807       0% 0.796494               56.2500             \n",
      " 12055     1      4750     1/111807       0% 0.698563               71.8750             \n",
      " 12169     1      4800     1/111807       0% 0.686087               81.2500             \n",
      " 12275     1      4850     1/111807       0% 0.895937               59.3750             \n",
      " 12386     1      4900     1/111807       0% 0.711678               71.8750             \n",
      " 12494     1      4950     1/111807       0% 0.955995               53.1250             \n",
      " 13153     1      5000     1/111807       0% 0.541135 0.872908      81.2500      61.1031\n",
      " 13153     1      5000     1/111807       0% 0.541135               81.2500             \n",
      " 13275     1      5050     1/111807       0% 0.826121               62.5000             \n",
      " 13398     1      5100     1/111807       0% 0.687442               65.6250             \n",
      " 13523     1      5150     1/111807       0% 0.719468               71.8750             \n",
      " 13655     1      5200     1/111807       0% 0.589516               81.2500             \n",
      " 13849     1      5250     1/111807       0% 0.695352               65.6250             \n",
      " 14080     1      5300     1/111807       0% 0.996861               65.6250             \n",
      " 14240     1      5350     1/111807       0% 0.699123               68.7500             \n",
      " 14380     1      5400     1/111807       0% 0.696160               62.5000             \n",
      " 14515     1      5450     1/111807       0% 0.626930               78.1250             \n",
      " 15214     1      5500     1/111807       0% 0.959925 0.870473      68.7500      61.3504\n",
      " 15214     1      5500     1/111807       0% 0.959925               68.7500             \n"
     ]
    }
   ],
   "source": [
    "% run train_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    31     0        50     1/111807       0% 1.402873               31.2500             \n",
      "    62     0       100     1/111807       0% 1.306998               43.7500             \n",
      "    98     0       150     1/111807       0% 1.348002               21.8750             \n",
      "   130     0       200     1/111807       0% 1.153292               56.2500             \n",
      "   170     0       250     1/111807       0% 0.941104               62.5000             \n",
      "   208     0       300     1/111807       0% 1.190249               43.7500             \n",
      "   247     0       350     1/111807       0% 1.073822               53.1250             \n",
      "   281     0       400     1/111807       0% 1.376545               43.7500             \n",
      "   318     0       450     1/111807       0% 1.140655               56.2500             \n",
      "   560     0       500     1/111807       0% 1.184331 1.292924      37.5000      41.0330\n",
      "   560     0       500     1/111807       0% 1.184331               37.5000             \n",
      "   600     0       550     1/111807       0% 1.038299               56.2500             \n",
      "   643     0       600     1/111807       0% 1.166740               40.6250             \n",
      "   683     0       650     1/111807       0% 1.053720               53.1250             \n",
      "   721     0       700     1/111807       0% 1.151801               50.0000             \n",
      "   759     0       750     1/111807       0% 0.946236               50.0000             \n",
      "   798     0       800     1/111807       0% 1.095934               56.2500             \n",
      "   839     0       850     1/111807       0% 0.872774               71.8750             \n",
      "   885     0       900     1/111807       0% 1.018365               56.2500             \n",
      "   932     0       950     1/111807       0% 0.916152               65.6250             \n",
      "  1192     0      1000     1/111807       0% 0.823018 1.023320      65.6250      54.4406\n",
      "  1192     0      1000     1/111807       0% 0.823018               65.6250             \n",
      "  1238     0      1050     1/111807       0% 0.975312               56.2500             \n",
      "  1285     0      1100     1/111807       0% 0.881480               68.7500             \n",
      "  1330     0      1150     1/111807       0% 0.897086               53.1250             \n",
      "  1379     0      1200     1/111807       0% 1.253154               34.3750             \n",
      "  1436     0      1250     1/111807       0% 0.902158               71.8750             \n",
      "  1493     0      1300     1/111807       0% 1.115405               37.5000             \n",
      "  1543     0      1350     1/111807       0% 0.947062               53.1250             \n",
      "  1597     0      1400     1/111807       0% 0.975617               56.2500             \n",
      "  1649     0      1450     1/111807       0% 0.813721               65.6250             \n",
      "  1924     0      1500     1/111807       0% 0.894181 0.977885      59.3750      56.2745\n",
      "  1924     0      1500     1/111807       0% 0.894181               59.3750             \n",
      "  1984     0      1550     1/111807       0% 0.844634               53.1250             \n",
      "  2043     0      1600     1/111807       0% 0.796985               65.6250             \n",
      "  2105     0      1650     1/111807       0% 0.853169               56.2500             \n",
      "  2165     0      1700     1/111807       0% 0.941012               56.2500             \n",
      "  2225     0      1750     1/111807       0% 0.996583               56.2500             \n",
      "  2290     0      1800     1/111807       0% 1.271827               34.3750             \n",
      "  2356     0      1850     1/111807       0% 0.785549               68.7500             \n",
      "  2423     0      1900     1/111807       0% 1.026439               59.3750             \n",
      "  2486     0      1950     1/111807       0% 0.840512               65.6250             \n",
      "  2790     0      2000     1/111807       0% 0.982225 0.916580      59.3750      58.8571\n",
      "  2790     0      2000     1/111807       0% 0.982225               59.3750             \n",
      "  2866     0      2050     1/111807       0% 0.928158               56.2500             \n",
      "  2946     0      2100     1/111807       0% 0.767474               68.7500             \n",
      "  3021     0      2150     1/111807       0% 0.655703               75.0000             \n",
      "  3099     0      2200     1/111807       0% 0.591537               78.1250             \n",
      "  3183     0      2250     1/111807       0% 0.776174               62.5000             \n",
      "  3275     0      2300     1/111807       0% 0.942478               56.2500             \n",
      "  3365     0      2350     1/111807       0% 1.299965               40.6250             \n",
      "  3454     0      2400     1/111807       0% 0.865413               59.3750             \n",
      "  3549     0      2450     1/111807       0% 0.979500               65.6250             \n",
      "  3933     0      2500     1/111807       0% 0.924010 0.895417      59.3750      59.9423\n",
      "  3933     0      2500     1/111807       0% 0.924010               59.3750             \n",
      "  4047     0      2550     1/111807       0% 0.782090               68.7500             \n",
      "  4160     0      2600     1/111807       0% 0.951138               53.1250             \n",
      "  4277     0      2650     1/111807       0% 0.739983               71.8750             \n",
      "  4398     0      2700     1/111807       0% 1.086559               50.0000             \n",
      "  4528     0      2750     1/111807       0% 0.797582               68.7500             \n",
      "  4658     0      2800     1/111807       0% 0.961802               59.3750             \n",
      "  4786     0      2850     1/111807       0% 1.021245               59.3750             \n",
      "  4923     0      2900     1/111807       0% 0.888557               62.5000             \n",
      "  5067     0      2950     1/111807       0% 0.852031               59.3750             \n",
      "  5575     0      3000     1/111807       0% 1.255761 0.880378      37.5000      60.5673\n",
      "  5575     0      3000     1/111807       0% 1.255761               37.5000             \n",
      "  5745     0      3050     1/111807       0% 0.845207               65.6250             \n",
      "  5921     0      3100     1/111807       0% 0.934020               62.5000             \n",
      "  6110     0      3150     1/111807       0% 0.993275               53.1250             \n",
      "  6304     0      3200     1/111807       0% 0.830894               71.8750             \n",
      "  6511     0      3250     1/111807       0% 0.843161               62.5000             \n",
      "  6743     0      3300     1/111807       0% 0.925512               56.2500             \n",
      "  7003     0      3350     1/111807       0% 0.727738               68.7500             \n",
      "  7299     0      3400     1/111807       0% 0.931926               68.7500             \n",
      "  7603     0      3450     1/111807       0% 0.967737               56.2500             \n",
      "  8499     1      3500     1/111807       0% 1.267528 0.881184      43.7500      60.6223\n",
      "  8499     1      3500     1/111807       0% 1.267528               43.7500             \n",
      "  8554     1      3550     1/111807       0% 0.954083               56.2500             \n",
      "  8614     1      3600     1/111807       0% 0.742288               75.0000             \n",
      "  8675     1      3650     1/111807       0% 0.994578               56.2500             \n",
      "  8734     1      3700     1/111807       0% 1.319553               43.7500             \n",
      "  8806     1      3750     1/111807       0% 1.086050               43.7500             \n",
      "  8878     1      3800     1/111807       0% 1.061279               46.8750             \n",
      "  8948     1      3850     1/111807       0% 1.010765               56.2500             \n",
      "  9019     1      3900     1/111807       0% 0.955104               65.6250             \n",
      "  9088     1      3950     1/111807       0% 0.932662               62.5000             \n",
      "  9684     1      4000     1/111807       0% 0.693972 0.878271      71.8750      60.7459\n",
      "  9684     1      4000     1/111807       0% 0.693972               71.8750             \n",
      "  9764     1      4050     1/111807       0% 0.619390               84.3750             \n",
      "  9846     1      4100     1/111807       0% 0.750925               81.2500             \n",
      "  9924     1      4150     1/111807       0% 0.877347               62.5000             \n",
      " 10002     1      4200     1/111807       0% 0.740288               68.7500             \n",
      " 10077     1      4250     1/111807       0% 0.961429               56.2500             \n",
      " 10156     1      4300     1/111807       0% 1.100608               50.0000             \n",
      " 10239     1      4350     1/111807       0% 0.829260               56.2500             \n",
      " 10328     1      4400     1/111807       0% 0.801501               65.6250             \n",
      " 10422     1      4450     1/111807       0% 0.876806               65.6250             \n",
      " 11033     1      4500     1/111807       0% 0.774808 0.886561      65.6250      61.2817\n",
      " 11033     1      4500     1/111807       0% 0.774808               65.6250             \n",
      " 11124     1      4550     1/111807       0% 0.704646               65.6250             \n",
      " 11214     1      4600     1/111807       0% 0.922435               56.2500             \n",
      " 11302     1      4650     1/111807       0% 0.931410               59.3750             \n",
      " 11401     1      4700     1/111807       0% 0.796494               56.2500             \n",
      " 11510     1      4750     1/111807       0% 0.698563               71.8750             \n",
      " 11619     1      4800     1/111807       0% 0.686087               81.2500             \n",
      " 11719     1      4850     1/111807       0% 0.895937               59.3750             \n",
      " 11840     1      4900     1/111807       0% 0.711678               71.8750             \n",
      " 11952     1      4950     1/111807       0% 0.955995               53.1250             \n",
      " 12595     1      5000     1/111807       0% 0.541135 0.872908      81.2500      61.1031\n",
      " 12595     1      5000     1/111807       0% 0.541135               81.2500             \n",
      " 12717     1      5050     1/111807       0% 0.826121               62.5000             \n",
      " 12837     1      5100     1/111807       0% 0.687442               65.6250             \n",
      " 12958     1      5150     1/111807       0% 0.719468               71.8750             \n",
      " 13078     1      5200     1/111807       0% 0.589516               81.2500             \n",
      " 13199     1      5250     1/111807       0% 0.695352               65.6250             \n",
      " 13329     1      5300     1/111807       0% 0.996861               65.6250             \n",
      " 13461     1      5350     1/111807       0% 0.699123               68.7500             \n",
      " 13596     1      5400     1/111807       0% 0.696160               62.5000             \n",
      " 13726     1      5450     1/111807       0% 0.626930               78.1250             \n",
      " 14378     1      5500     1/111807       0% 0.959925 0.870473      68.7500      61.3504\n",
      " 14378     1      5500     1/111807       0% 0.959925               68.7500             \n",
      " 14525     1      5550     1/111807       0% 0.615943               68.7500             \n",
      " 14673     1      5600     1/111807       0% 0.905178               65.6250             \n",
      " 14816     1      5650     1/111807       0% 0.803641               56.2500             \n",
      " 14966     1      5700     1/111807       0% 0.986234               50.0000             \n",
      " 15120     1      5750     1/111807       0% 0.578478               81.2500             \n",
      " 15283     1      5800     1/111807       0% 0.817714               68.7500             \n",
      " 15451     1      5850     1/111807       0% 0.822967               62.5000             \n",
      " 15613     1      5900     1/111807       0% 0.928347               59.3750             \n",
      " 15780     1      5950     1/111807       0% 0.764771               62.5000             \n",
      " 16465     1      6000     1/111807       0% 0.599571 0.851842      78.1250      62.5661\n",
      " 16465     1      6000     1/111807       0% 0.599571               78.1250             \n",
      " 16641     1      6050     1/111807       0% 0.850119               59.3750             \n",
      " 16816     1      6100     1/111807       0% 0.631338               81.2500             \n",
      " 16995     1      6150     1/111807       0% 0.640232               71.8750             \n",
      " 17183     1      6200     1/111807       0% 0.677295               71.8750             \n",
      " 17379     1      6250     1/111807       0% 0.820049               65.6250             \n",
      " 17574     1      6300     1/111807       0% 0.908870               59.3750             \n",
      " 17767     1      6350     1/111807       0% 0.785772               56.2500             \n",
      " 17971     1      6400     1/111807       0% 0.752353               68.7500             \n",
      " 18189     1      6450     1/111807       0% 0.857516               56.2500             \n",
      " 18915     1      6500     1/111807       0% 0.832964 0.869830      62.5000      61.3916\n",
      " 18915     1      6500     1/111807       0% 0.832964               62.5000             \n",
      " 19145     1      6550     1/111807       0% 0.725472               65.6250             \n",
      " 19388     1      6600     1/111807       0% 0.840476               65.6250             \n",
      " 19626     1      6650     1/111807       0% 0.886390               65.6250             \n",
      " 19878     1      6700     1/111807       0% 0.876443               56.2500             \n",
      " 20136     1      6750     1/111807       0% 1.005891               53.1250             \n",
      " 20410     1      6800     1/111807       0% 0.805403               71.8750             \n",
      " 20689     1      6850     1/111807       0% 0.822639               56.2500             \n",
      " 20998     1      6900     1/111807       0% 0.883058               56.2500             \n",
      " 21305     1      6950     1/111807       0% 0.741926               71.8750             \n",
      " 22073     2      7000     1/111807       0% 0.717592 0.861711      71.8750      61.5015\n",
      " 22073     2      7000     1/111807       0% 0.717592               71.8750             \n",
      " 22129     2      7050     1/111807       0% 0.765921               68.7500             \n",
      " 22185     2      7100     1/111807       0% 1.015259               65.6250             \n",
      " 22242     2      7150     1/111807       0% 0.916465               59.3750             \n",
      " 22302     2      7200     1/111807       0% 0.750749               68.7500             \n",
      " 22367     2      7250     1/111807       0% 0.618438               78.1250             \n",
      " 22435     2      7300     1/111807       0% 0.762978               68.7500             \n",
      " 22501     2      7350     1/111807       0% 0.879211               59.3750             \n",
      " 22568     2      7400     1/111807       0% 0.761333               68.7500             \n",
      " 22633     2      7450     1/111807       0% 0.821022               62.5000             \n",
      " 23194     2      7500     1/111807       0% 0.793475 0.867551      59.3750      61.8312\n",
      " 23194     2      7500     1/111807       0% 0.793475               59.3750             \n",
      " 23273     2      7550     1/111807       0% 0.764459               65.6250             \n",
      " 23350     2      7600     1/111807       0% 0.944145               56.2500             \n",
      " 23426     2      7650     1/111807       0% 0.833606               46.8750             \n",
      " 23501     2      7700     1/111807       0% 0.686409               71.8750             \n",
      " 23572     2      7750     1/111807       0% 0.663343               75.0000             \n",
      " 23647     2      7800     1/111807       0% 0.945786               59.3750             \n",
      " 23729     2      7850     1/111807       0% 0.814852               65.6250             \n",
      " 23816     2      7900     1/111807       0% 0.549218               81.2500             \n",
      " 23903     2      7950     1/111807       0% 0.836380               56.2500             \n",
      " 24491     2      8000     1/111807       0% 0.538142 0.862989      68.7500      62.2570\n",
      " 24491     2      8000     1/111807       0% 0.538142               68.7500             \n",
      " 24582     2      8050     1/111807       0% 0.810757               71.8750             \n",
      " 24672     2      8100     1/111807       0% 0.726934               71.8750             \n",
      " 24759     2      8150     1/111807       0% 0.600020               78.1250             \n",
      " 24861     2      8200     1/111807       0% 0.665741               71.8750             \n",
      " 24971     2      8250     1/111807       0% 0.752608               59.3750             \n",
      " 25080     2      8300     1/111807       0% 0.866303               56.2500             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25182     2      8350     1/111807       0% 0.704183               71.8750             \n",
      " 25287     2      8400     1/111807       0% 0.706623               62.5000             \n",
      " 25390     2      8450     1/111807       0% 0.673284               62.5000             \n",
      " 26015     2      8500     1/111807       0% 0.719957 0.871188      59.3750      62.3738\n",
      " 26015     2      8500     1/111807       0% 0.719957               59.3750             \n",
      " 26140     2      8550     1/111807       0% 0.555040               78.1250             \n",
      " 26264     2      8600     1/111807       0% 0.713406               56.2500             \n",
      " 26390     2      8650     1/111807       0% 0.664272               71.8750             \n",
      " 26515     2      8700     1/111807       0% 0.743773               75.0000             \n",
      " 26642     2      8750     1/111807       0% 0.808523               71.8750             \n",
      " 26781     2      8800     1/111807       0% 0.765208               59.3750             \n",
      " 26921     2      8850     1/111807       0% 0.975186               59.3750             \n",
      " 27063     2      8900     1/111807       0% 0.820581               59.3750             \n",
      " 27201     2      8950     1/111807       0% 0.763949               56.2500             \n",
      " 27879     2      9000     1/111807       0% 0.877181 0.882122      56.2500      61.5221\n",
      " 27879     2      9000     1/111807       0% 0.877181               56.2500             \n",
      " 28038     2      9050     1/111807       0% 0.687497               59.3750             \n",
      " 28199     2      9100     1/111807       0% 0.725643               62.5000             \n",
      " 28356     2      9150     1/111807       0% 0.870192               62.5000             \n",
      " 28521     2      9200     1/111807       0% 0.878668               56.2500             \n",
      " 28687     2      9250     1/111807       0% 0.691775               65.6250             \n",
      " 28866     2      9300     1/111807       0% 0.627616               65.6250             \n",
      " 29046     2      9350     1/111807       0% 0.877877               68.7500             \n",
      " 29223     2      9400     1/111807       0% 0.675468               68.7500             \n",
      " 29411     2      9450     1/111807       0% 0.562248               68.7500             \n",
      " 30142     2      9500     1/111807       0% 0.699476 0.859912      65.6250      62.4699\n",
      " 30142     2      9500     1/111807       0% 0.699476               65.6250             \n",
      " 30337     2      9550     1/111807       0% 0.873191               68.7500             \n",
      " 30532     2      9600     1/111807       0% 0.658008               65.6250             \n",
      " 30735     2      9650     1/111807       0% 0.601548               78.1250             \n",
      " 30941     2      9700     1/111807       0% 0.825911               68.7500             \n",
      " 31155     2      9750     1/111807       0% 0.670625               71.8750             \n",
      " 31371     2      9800     1/111807       0% 0.813878               62.5000             \n",
      " 31587     2      9850     1/111807       0% 0.484914               81.2500             \n",
      " 31814     2      9900     1/111807       0% 0.661917               68.7500             \n",
      " 32048     2      9950     1/111807       0% 0.493181               84.3750             \n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[100,500] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\treehan\\train_2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5498\u001b[0m   \"\"\"\n\u001b[0;32m   5499\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5500\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\treehan\\train_2.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\treehan\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m                 \u001b[0miterations\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m                 \u001b[0mbatch_train_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_train_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                 mean_loss(batch_train_loss.numpy(),\n",
      "\u001b[1;32m~\\treehan\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         self._optimizer.apply_gradients(zip(gradients, self._model.variables),\n\u001b[0;32m    140\u001b[0m                                     global_step=tf.train.get_global_step())\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m    765\u001b[0m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0;32m    766\u001b[0m         \u001b[0m_default_vspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         output_gradients=output_gradients)\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(vspace, tape, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m     61\u001b[0m   \"\"\"\n\u001b[0;32m     62\u001b[0m   return pywrap_tensorflow.TFE_Py_TapeGradient(\n\u001b[1;32m---> 63\u001b[1;33m       tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgrad_fn\u001b[1;34m(*orig_outputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0morig_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     result = _magic_gradient_function(op_name, attrs, num_inputs,\n\u001b[1;32m--> 147\u001b[1;33m                                       op_inputs, op_outputs, orig_outputs)\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_tracing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m       print(\"Gradient for\", op_name, \"inputs\", op_inputs, \"output_grads\",\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_magic_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1045\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   4591\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4592\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4593\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[100,500] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "% run train_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    41     0        50     1/111807       0% 1.402873               31.2500             \n",
      "    76     0       100     1/111807       0% 1.306998               43.7500             \n",
      "   117     0       150     1/111807       0% 1.348002               21.8750             \n",
      "   155     0       200     1/111807       0% 1.153292               56.2500             \n",
      "   202     0       250     1/111807       0% 0.941104               62.5000             \n",
      "   246     0       300     1/111807       0% 1.190249               43.7500             \n",
      "   288     0       350     1/111807       0% 1.073822               53.1250             \n",
      "   326     0       400     1/111807       0% 1.376545               43.7500             \n",
      "   379     0       450     1/111807       0% 1.140655               56.2500             \n",
      "   678     0       500     1/111807       0% 1.184331 1.292924      37.5000      41.0330\n",
      "   678     0       500     1/111807       0% 1.184331               37.5000             \n",
      "   728     0       550     1/111807       0% 1.038299               56.2500             \n",
      "   780     0       600     1/111807       0% 1.166740               40.6250             \n",
      "   828     0       650     1/111807       0% 1.053720               53.1250             \n",
      "   876     0       700     1/111807       0% 1.151801               50.0000             \n",
      "   922     0       750     1/111807       0% 0.946236               50.0000             \n",
      "   971     0       800     1/111807       0% 1.095934               56.2500             \n",
      "  1020     0       850     1/111807       0% 0.872774               71.8750             \n",
      "  1073     0       900     1/111807       0% 1.018365               56.2500             \n",
      "  1130     0       950     1/111807       0% 0.916152               65.6250             \n"
     ]
    }
   ],
   "source": [
    "% run train_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    39     0        50     1/111807       0% 1.409763               34.3750             \n",
      "    81     0       100     1/111807       0% 1.194308               43.7500             \n",
      "   125     0       150     1/111807       0% 1.301656               40.6250             \n",
      "   167     0       200     1/111807       0% 1.054960               65.6250             \n",
      "   217     0       250     1/111807       0% 0.946479               59.3750             \n",
      "   264     0       300     1/111807       0% 1.191928               50.0000             \n",
      "   311     0       350     1/111807       0% 0.897799               59.3750             \n",
      "   356     0       400     1/111807       0% 1.149476               46.8750             \n",
      "   405     0       450     1/111807       0% 1.041364               53.1250             \n",
      "   762     0       500     1/111807       0% 1.058244 1.034972      46.8750      54.1589\n",
      "   762     0       500     1/111807       0% 1.058244               46.8750             \n",
      "   822     0       550     1/111807       0% 0.909412               59.3750             \n",
      "   880     0       600     1/111807       0% 1.014757               59.3750             \n",
      "   934     0       650     1/111807       0% 1.012486               59.3750             \n",
      "   987     0       700     1/111807       0% 0.997619               56.2500             \n",
      "  1039     0       750     1/111807       0% 0.903499               56.2500             \n",
      "  1094     0       800     1/111807       0% 0.894306               59.3750             \n",
      "  1151     0       850     1/111807       0% 0.912712               59.3750             \n",
      "  1214     0       900     1/111807       0% 0.942743               56.2500             \n",
      "  1281     0       950     1/111807       0% 0.979411               62.5000             \n",
      "  1799     0      1000     1/111807       0% 0.810787 0.934910      56.2500      58.3282\n",
      "  1799     0      1000     1/111807       0% 0.810787               56.2500             \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\treehanv3\\train_2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5498\u001b[0m   \"\"\"\n\u001b[0;32m   5499\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5500\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\treehanv3\\train_2.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\treehanv3\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                 \u001b[0miterations\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[0mbatch_train_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_train_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                 mean_loss(batch_train_loss.numpy(),\n",
      "\u001b[1;32m~\\treehanv3\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         self._optimizer.apply_gradients(zip(gradients, self._model.variables),\n\u001b[0;32m    143\u001b[0m                                     global_step=tf.train.get_global_step())\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m    765\u001b[0m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0;32m    766\u001b[0m         \u001b[0m_default_vspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         output_gradients=output_gradients)\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(vspace, tape, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m     61\u001b[0m   \"\"\"\n\u001b[0;32m     62\u001b[0m   return pywrap_tensorflow.TFE_Py_TapeGradient(\n\u001b[1;32m---> 63\u001b[1;33m       tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgrad_fn\u001b[1;34m(*orig_outputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0morig_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     result = _magic_gradient_function(op_name, attrs, num_inputs,\n\u001b[1;32m--> 147\u001b[1;33m                                       op_inputs, op_outputs, orig_outputs)\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_tracing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m       print(\"Gradient for\", op_name, \"inputs\", op_inputs, \"output_grads\",\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_magic_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_TransposeGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    544\u001b[0m   \u001b[1;34m\"\"\"Returns unshuffle(grad).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m   \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvert_permutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36minvert_permutation\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   4247\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   4248\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4249\u001b[1;33m         \"InvertPermutation\", name, _ctx._post_execution_callbacks, x)\n\u001b[0m\u001b[0;32m   4250\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4251\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "% run train_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    50     0        50     1/111807       0% 1.397479               31.2500             \n",
      "   100     0       100     1/111807       0% 1.145076               53.1250             \n",
      "   158     0       150     1/111807       0% 1.211776               34.3750             \n",
      "   206     0       200     1/111807       0% 1.048605               62.5000             \n",
      "   265     0       250     1/111807       0% 0.874604               62.5000             \n",
      "   325     0       300     1/111807       0% 1.092332               46.8750             \n",
      "   391     0       350     1/111807       0% 0.891590               68.7500             \n",
      "   450     0       400     1/111807       0% 1.178613               34.3750             \n",
      "   509     0       450     1/111807       0% 1.066315               46.8750             \n",
      "   942     0       500     1/111807       0% 1.103592 1.038527      50.0000      54.2070\n",
      "   942     0       500     1/111807       0% 1.103592               50.0000             \n",
      "  1011     0       550     1/111807       0% 0.881613               56.2500             \n",
      "  1077     0       600     1/111807       0% 1.033672               50.0000             \n",
      "  1133     0       650     1/111807       0% 0.947738               56.2500             \n",
      "  1188     0       700     1/111807       0% 0.970518               50.0000             \n",
      "  1242     0       750     1/111807       0% 0.799009               71.8750             \n",
      "  1300     0       800     1/111807       0% 0.915861               62.5000             \n",
      "  1359     0       850     1/111807       0% 0.853661               50.0000             \n",
      "  1426     0       900     1/111807       0% 0.931745               50.0000             \n",
      "  1499     0       950     1/111807       0% 0.916242               59.3750             \n"
     ]
    }
   ],
   "source": [
    "% run train_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    39     0        50     1/111807       0% 1.394575               31.2500             \n",
      "    78     0       100     1/111807       0% 1.153295               40.6250             \n",
      "   121     0       150     1/111807       0% 1.183289               50.0000             \n",
      "   160     0       200     1/111807       0% 0.958083               53.1250             \n",
      "   208     0       250     1/111807       0% 0.893275               65.6250             \n",
      "   253     0       300     1/111807       0% 1.181118               46.8750             \n",
      "   300     0       350     1/111807       0% 0.812166               75.0000             \n",
      "   344     0       400     1/111807       0% 1.225780               40.6250             \n",
      "   392     0       450     1/111807       0% 1.128042               46.8750             \n",
      "   745     0       500     1/111807       0% 1.097893 1.041026      40.6250      52.9295\n",
      "   745     0       500     1/111807       0% 1.097893               40.6250             \n",
      "   802     0       550     1/111807       0% 0.864479               71.8750             \n",
      "   862     0       600     1/111807       0% 1.029043               59.3750             \n",
      "   916     0       650     1/111807       0% 1.067304               50.0000             \n",
      "   970     0       700     1/111807       0% 1.085547               56.2500             \n",
      "  1022     0       750     1/111807       0% 0.836040               53.1250             \n",
      "  1087     0       800     1/111807       0% 0.965699               56.2500             \n",
      "  1157     0       850     1/111807       0% 0.780032               65.6250             \n",
      "  1225     0       900     1/111807       0% 0.923772               59.3750             \n",
      "  1294     0       950     1/111807       0% 0.990373               62.5000             \n",
      "  1736     0      1000     1/111807       0% 0.771653 0.933871      68.7500      57.8680\n",
      "  1736     0      1000     1/111807       0% 0.771653               68.7500             \n",
      "  1804     0      1050     1/111807       0% 0.921542               62.5000             \n",
      "  1871     0      1100     1/111807       0% 0.949756               68.7500             \n",
      "  1936     0      1150     1/111807       0% 0.865029               59.3750             \n",
      "  2006     0      1200     1/111807       0% 1.321935               21.8750             \n",
      "  2086     0      1250     1/111807       0% 0.791538               65.6250             \n",
      "  2167     0      1300     1/111807       0% 1.126954               43.7500             \n",
      "  2239     0      1350     1/111807       0% 0.806331               62.5000             \n",
      "  2315     0      1400     1/111807       0% 0.924392               50.0000             \n",
      "  2389     0      1450     1/111807       0% 0.823220               62.5000             \n",
      "  2819     0      1500     1/111807       0% 0.927947 0.909287      59.3750      59.2417\n",
      "  2819     0      1500     1/111807       0% 0.927947               59.3750             \n",
      "  2909     0      1550     1/111807       0% 0.806859               62.5000             \n",
      "  2998     0      1600     1/111807       0% 0.836768               65.6250             \n",
      "  3091     0      1650     1/111807       0% 0.811177               62.5000             \n",
      "  3182     0      1700     1/111807       0% 1.026101               62.5000             \n",
      "  3272     0      1750     1/111807       0% 0.984315               53.1250             \n",
      "  3388     0      1800     1/111807       0% 1.071278               50.0000             \n",
      "  3496     0      1850     1/111807       0% 0.812440               68.7500             \n",
      "  3615     0      1900     1/111807       0% 0.901175               59.3750             \n",
      "  3716     0      1950     1/111807       0% 0.716922               68.7500             \n",
      "  4219     0      2000     1/111807       0% 0.971330 0.890645      56.2500      60.4094\n",
      "  4219     0      2000     1/111807       0% 0.971330               56.2500             \n",
      "  4354     0      2050     1/111807       0% 1.069973               46.8750             \n",
      "  4515     0      2100     1/111807       0% 0.770878               68.7500             \n",
      "  4643     0      2150     1/111807       0% 0.704002               75.0000             \n",
      "  4774     0      2200     1/111807       0% 0.642061               71.8750             \n",
      "  4915     0      2250     1/111807       0% 0.719508               62.5000             \n",
      "  5067     0      2300     1/111807       0% 0.968727               53.1250             \n",
      "  5216     0      2350     1/111807       0% 1.167945               43.7500             \n",
      "  5367     0      2400     1/111807       0% 0.832279               71.8750             \n",
      "  5528     0      2450     1/111807       0% 1.009353               62.5000             \n",
      "  6214     0      2500     1/111807       0% 0.920001 0.868935      50.0000      61.1512\n",
      "  6214     0      2500     1/111807       0% 0.920001               50.0000             \n",
      "  6412     0      2550     1/111807       0% 0.885889               59.3750             \n",
      "  6608     0      2600     1/111807       0% 0.921983               59.3750             \n",
      "  6812     0      2650     1/111807       0% 0.784605               71.8750             \n",
      "  7019     0      2700     1/111807       0% 0.938788               65.6250             \n",
      "  7238     0      2750     1/111807       0% 0.925211               59.3750             \n",
      "  7466     0      2800     1/111807       0% 0.761953               56.2500             \n",
      "  7701     0      2850     1/111807       0% 1.061600               53.1250             \n",
      "  7957     0      2900     1/111807       0% 0.871711               53.1250             \n",
      "  8227     0      2950     1/111807       0% 0.770035               65.6250             \n",
      "  9193     0      3000     1/111807       0% 0.955022 0.870530      62.5000      61.4328\n",
      "  9193     0      3000     1/111807       0% 0.955022               62.5000             \n",
      "  9506     0      3050     1/111807       0% 0.673157               65.6250             \n",
      "  9831     0      3100     1/111807       0% 1.036245               53.1250             \n",
      " 10163     0      3150     1/111807       0% 0.954176               53.1250             \n",
      " 10589     0      3200     1/111807       0% 0.756335               68.7500             \n"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    43     0        50     1/111807       0% 1.397798               31.2500             \n",
      "    83     0       100     1/111807       0% 1.133590               46.8750             \n",
      "   126     0       150     1/111807       0% 1.221929               34.3750             \n",
      "   166     0       200     1/111807       0% 1.018339               62.5000             \n",
      "   216     0       250     1/111807       0% 0.902768               65.6250             \n",
      "   262     0       300     1/111807       0% 1.113191               53.1250             \n",
      "   310     0       350     1/111807       0% 0.803389               78.1250             \n",
      "   355     0       400     1/111807       0% 1.196827               34.3750             \n",
      "   405     0       450     1/111807       0% 1.061760               56.2500             \n",
      "   763     0       500     1/111807       0% 1.117557 1.043639      50.0000      52.3044\n",
      "   763     0       500     1/111807       0% 1.117557               50.0000             \n",
      "   820     0       550     1/111807       0% 0.820683               65.6250             \n",
      "   878     0       600     1/111807       0% 1.027603               62.5000             \n",
      "   931     0       650     1/111807       0% 0.936655               65.6250             \n",
      "   983     0       700     1/111807       0% 1.010597               56.2500             \n",
      "  1035     0       750     1/111807       0% 0.885491               53.1250             \n",
      "  1089     0       800     1/111807       0% 0.965528               56.2500             \n",
      "  1144     0       850     1/111807       0% 0.815562               62.5000             \n",
      "  1205     0       900     1/111807       0% 0.870210               62.5000             \n",
      "  1269     0       950     1/111807       0% 0.982799               65.6250             \n",
      "  1664     0      1000     1/111807       0% 0.720673 0.937132      75.0000      58.0672\n",
      "  1664     0      1000     1/111807       0% 0.720673               75.0000             \n",
      "  1731     0      1050     1/111807       0% 0.945763               53.1250             \n",
      "  1797     0      1100     1/111807       0% 0.968669               68.7500             \n",
      "  1861     0      1150     1/111807       0% 0.851503               50.0000             \n",
      "  1929     0      1200     1/111807       0% 1.228275               28.1250             \n",
      "  2009     0      1250     1/111807       0% 0.806304               65.6250             \n",
      "  2090     0      1300     1/111807       0% 1.143095               53.1250             \n",
      "  2160     0      1350     1/111807       0% 0.820056               68.7500             \n",
      "  2238     0      1400     1/111807       0% 0.958679               53.1250             \n",
      "  2312     0      1450     1/111807       0% 0.778370               65.6250             \n",
      "  2760     0      1500     1/111807       0% 0.865017 0.912381      59.3750      59.2967\n",
      "  2760     0      1500     1/111807       0% 0.865017               59.3750             \n",
      "  2866     0      1550     1/111807       0% 0.832388               62.5000             \n",
      "  2970     0      1600     1/111807       0% 0.828054               62.5000             \n",
      "  3071     0      1650     1/111807       0% 0.741642               65.6250             \n",
      "  3173     0      1700     1/111807       0% 1.023971               56.2500             \n",
      "  3267     0      1750     1/111807       0% 1.062562               50.0000             \n",
      "  3370     0      1800     1/111807       0% 1.126369               40.6250             \n",
      "  3537     0      1850     1/111807       0% 0.806632               71.8750             \n",
      "  3690     0      1900     1/111807       0% 0.985762               65.6250             \n",
      "  3812     0      1950     1/111807       0% 0.773804               62.5000             \n",
      "  4365     0      2000     1/111807       0% 0.872050 0.891840      62.5000      60.3613\n",
      "  4365     0      2000     1/111807       0% 0.872050               62.5000             \n",
      "  4505     0      2050     1/111807       0% 0.938324               56.2500             \n",
      "  4651     0      2100     1/111807       0% 0.778462               68.7500             \n",
      "  4781     0      2150     1/111807       0% 0.671861               59.3750             \n",
      "  4923     0      2200     1/111807       0% 0.612868               68.7500             \n",
      "  5084     0      2250     1/111807       0% 0.796469               65.6250             \n",
      "  5307     0      2300     1/111807       0% 0.888901               62.5000             \n",
      "  5524     0      2350     1/111807       0% 1.186171               34.3750             \n",
      "  5742     0      2400     1/111807       0% 0.794306               62.5000             \n",
      "  5965     0      2450     1/111807       0% 0.976044               68.7500             \n",
      "  6758     0      2500     1/111807       0% 0.938074 0.871372      53.1250      61.2817\n",
      "  6758     0      2500     1/111807       0% 0.938074               53.1250             \n",
      "  6968     0      2550     1/111807       0% 0.853562               68.7500             \n",
      "  7226     0      2600     1/111807       0% 0.871508               59.3750             \n",
      "  7510     0      2650     1/111807       0% 0.821353               71.8750             \n",
      "  7736     0      2700     1/111807       0% 0.942942               62.5000             \n",
      "  7982     0      2750     1/111807       0% 0.908997               65.6250             \n",
      "  8228     0      2800     1/111807       0% 0.802234               59.3750             \n",
      "  8473     0      2850     1/111807       0% 1.075312               46.8750             \n",
      "  8798     0      2900     1/111807       0% 0.924004               56.2500             \n",
      "  9131     0      2950     1/111807       0% 0.753904               65.6250             \n",
      " 10388     0      3000     1/111807       0% 0.971502 0.868816      56.2500      61.6114\n",
      " 10388     0      3000     1/111807       0% 0.971502               56.2500             \n",
      " 10816     0      3050     1/111807       0% 0.770370               65.6250             \n"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    53     0        50     1/111807       0% 1.372396               31.2500             \n",
      "   109     0       100     1/111807       0% 1.162987               34.3750             \n",
      "   175     0       150     1/111807       0% 1.151235               31.2500             \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5498\u001b[0m   \"\"\"\n\u001b[0;32m   5499\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5500\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                 \u001b[0miterations\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m                 \u001b[0mbatch_train_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_train_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 mean_loss(batch_train_loss.numpy(),\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;31m#reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;31m#loss1 = loss + reg_losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         self._optimizer.apply_gradients(zip(gradients, self._model.variables),\n\u001b[0;32m    111\u001b[0m                                     global_step=tf.train.get_global_step())\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m    765\u001b[0m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0;32m    766\u001b[0m         \u001b[0m_default_vspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         output_gradients=output_gradients)\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(vspace, tape, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m     61\u001b[0m   \"\"\"\n\u001b[0;32m     62\u001b[0m   return pywrap_tensorflow.TFE_Py_TapeGradient(\n\u001b[1;32m---> 63\u001b[1;33m       tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgrad_fn\u001b[1;34m(*orig_outputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0morig_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     result = _magic_gradient_function(op_name, attrs, num_inputs,\n\u001b[1;32m--> 147\u001b[1;33m                                       op_inputs, op_outputs, orig_outputs)\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_tracing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m       print(\"Gradient for\", op_name, \"inputs\", op_inputs, \"output_grads\",\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_magic_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_SigmoidGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    717\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msigmoid_grad\u001b[1;34m(y, dy, name)\u001b[0m\n\u001b[0;32m   7319\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   7320\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"SigmoidGrad\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7321\u001b[1;33m         name, _ctx._post_execution_callbacks, y, dy)\n\u001b[0m\u001b[0;32m   7322\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    62     0        50     1/111807       0% 1.318751               43.7500             \n",
      "   113     0       100     1/111807       0% 1.146141               31.2500             \n",
      "   167     0       150     1/111807       0% 1.144380               43.7500             \n",
      "   222     0       200     1/111807       0% 1.045483               53.1250             \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36msplit_v\u001b[1;34m(value, size_splits, axis, num_split, name)\u001b[0m\n\u001b[0;32m   9570\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"num_split\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9571\u001b[1;33m         num_split)\n\u001b[0m\u001b[0;32m   9572\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5498\u001b[0m   \"\"\"\n\u001b[0;32m   5499\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5500\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                 \u001b[0miterations\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m                 \u001b[0mbatch_train_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_train_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 mean_loss(batch_train_loss.numpy(),\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;31m#reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;31m#loss1 = loss + reg_losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         self._optimizer.apply_gradients(zip(gradients, self._model.variables),\n\u001b[0;32m    111\u001b[0m                                     global_step=tf.train.get_global_step())\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m    765\u001b[0m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0;32m    766\u001b[0m         \u001b[0m_default_vspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         output_gradients=output_gradients)\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(vspace, tape, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m     61\u001b[0m   \"\"\"\n\u001b[0;32m     62\u001b[0m   return pywrap_tensorflow.TFE_Py_TapeGradient(\n\u001b[1;32m---> 63\u001b[1;33m       tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgrad_fn\u001b[1;34m(*orig_outputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0morig_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     result = _magic_gradient_function(op_name, attrs, num_inputs,\n\u001b[1;32m--> 147\u001b[1;33m                                       op_inputs, op_outputs, orig_outputs)\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_tracing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m       print(\"Gradient for\", op_name, \"inputs\", op_inputs, \"output_grads\",\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_magic_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_ConcatGradV2\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_ConcatGradV2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m   return _ConcatGradHelper(\n\u001b[1;32m--> 224\u001b[1;33m       op, grad, start_value_index=0, end_value_index=-1, dim_index=-1)\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_ConcatGradHelper\u001b[1;34m(op, grad, start_value_index, end_value_index, dim_index)\u001b[0m\n\u001b[0;32m    115\u001b[0m       sizes = pywrap_tensorflow.TFE_Py_TensorShapeSlice(input_values,\n\u001b[0;32m    116\u001b[0m                                                         non_neg_concat_dim)\n\u001b[1;32m--> 117\u001b[1;33m       \u001b[0mout_grads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_neg_concat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(value, num_or_size_splits, axis, num, name)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m   return gen_array_ops.split_v(\n\u001b[1;32m-> 1401\u001b[1;33m       value=value, size_splits=size_splits, axis=axis, num_split=num, name=name)\n\u001b[0m\u001b[0;32m   1402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36msplit_v\u001b[1;34m(value, size_splits, axis, num_split, name)\u001b[0m\n\u001b[0;32m   9573\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9574\u001b[0m       return split_v_eager_fallback(\n\u001b[1;32m-> 9575\u001b[1;33m           value, size_splits, axis, num_split=num_split, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m   9576\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9577\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36msplit_v_eager_fallback\u001b[1;34m(value, size_splits, axis, num_split, name, ctx)\u001b[0m\n\u001b[0;32m   9594\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"num_split\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"T\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tlen\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_Tlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9595\u001b[0m   _result = _execute.execute(b\"SplitV\", num_split, inputs=_inputs_flat,\n\u001b[1;32m-> 9596\u001b[1;33m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[0;32m   9597\u001b[0m   _execute.record_gradient(\n\u001b[0;32m   9598\u001b[0m       \"SplitV\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    49     0        50     1/111807       0% 1.337379               37.5000             \n",
      "    99     0       100     1/111807       0% 1.125705               31.2500             \n",
      "   157     0       150     1/111807       0% 1.126726               40.6250             \n",
      "   208     0       200     1/111807       0% 1.058143               43.7500             \n",
      "   268     0       250     1/111807       0% 0.846069               68.7500             \n",
      "   325     0       300     1/111807       0% 1.066023               59.3750             \n",
      "   385     0       350     1/111807       0% 0.869061               56.2500             \n",
      "   440     0       400     1/111807       0% 1.192257               43.7500             \n",
      "   500     0       450     1/111807       0% 1.156952               46.8750             \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ConcatV2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m         name, _ctx._post_execution_callbacks, values, axis)\n\u001b[0m\u001b[0;32m   1120\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5498\u001b[0m   \"\"\"\n\u001b[0;32m   5499\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5500\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    228\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                     dev_loss, dev_frac_correct = _evaluate_on_dataset(\n\u001b[1;32m--> 230\u001b[1;33m               val_dataset, trainer, use_gpu)\n\u001b[0m\u001b[0;32m    231\u001b[0m                     print(dev_log_template.format(\n\u001b[0;32m    232\u001b[0m                           \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36m_evaluate_on_dataset\u001b[1;34m(val_dataset, trainer, use_gpu)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \"\"\"\n\u001b[0;32m    313\u001b[0m     \u001b[1;31m# Actually call the layer (optionally building it).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_uses_inputs_arg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m             raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         sentence_level_outputs = self.sentence_encoder(sentence_embeddings, transitions,\n\u001b[1;32m---> 59\u001b[1;33m                            training = is_training)\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m#generate document level embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \"\"\"\n\u001b[0;32m    313\u001b[0m     \u001b[1;31m# Actually call the layer (optionally building it).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_uses_inputs_arg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m             raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\SPINN.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, buffers, transitions, training)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mreducer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlefts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[0mreduced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreducer_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \"\"\"\n\u001b[0;32m    313\u001b[0m     \u001b[1;31m# Actually call the layer (optionally building it).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_uses_inputs_arg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m             raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\SPINN.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, left_in, right_in, training, tracking)\u001b[0m\n\u001b[0;32m     58\u001b[0m       \u001b[0mOutput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlength\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mEach\u001b[0m \u001b[0mitem\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \"\"\"\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_bundle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_bundle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[0mlstm_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\SPINN.py\u001b[0m in \u001b[0;36m_bundle\u001b[1;34m(lstm_iter)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meach\u001b[0m \u001b[0mof\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m   \"\"\"\n\u001b[1;32m---> 16\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1187\u001b[0m               tensor_shape.scalar())\n\u001b[0;32m   1188\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       return concat_v2_eager_fallback(\n\u001b[1;32m-> 1123\u001b[1;33m           values, axis, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m   1124\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2_eager_fallback\u001b[1;34m(values, axis, name, ctx)\u001b[0m\n\u001b[0;32m   1145\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"N\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_N\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"T\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tidx\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_Tidx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m   _result = _execute.execute(b\"ConcatV2\", 1, inputs=_inputs_flat,\n\u001b[1;32m-> 1147\u001b[1;33m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[0;32m   1148\u001b[0m   _execute.record_gradient(\n\u001b[0;32m   1149\u001b[0m       \"ConcatV2\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    44     0        50     1/111807       0% 1.333002               40.6250             \n",
      "    88     0       100     1/111807       0% 1.115711               31.2500             \n",
      "   134     0       150     1/111807       0% 1.145190               40.6250             \n",
      "   176     0       200     1/111807       0% 1.047686               50.0000             \n",
      "   227     0       250     1/111807       0% 0.883400               62.5000             \n",
      "   275     0       300     1/111807       0% 1.108779               53.1250             \n",
      "   324     0       350     1/111807       0% 0.891302               56.2500             \n",
      "   371     0       400     1/111807       0% 1.307465               40.6250             \n",
      "   422     0       450     1/111807       0% 1.074218               46.8750             \n",
      "   770     0       500     1/111807       0% 1.119506 1.065749      50.0000      53.0668\n",
      "   770     0       500     1/111807       0% 1.119506               50.0000             \n",
      "   829     0       550     1/111807       0% 0.926332               46.8750             \n",
      "   888     0       600     1/111807       0% 0.929391               53.1250             \n",
      "   944     0       650     1/111807       0% 1.009380               56.2500             \n",
      "  1002     0       700     1/111807       0% 0.956067               59.3750             \n",
      "  1057     0       750     1/111807       0% 0.845119               62.5000             \n",
      "  1115     0       800     1/111807       0% 0.810447               59.3750             \n",
      "  1173     0       850     1/111807       0% 0.764745               71.8750             \n",
      "  1236     0       900     1/111807       0% 0.866683               59.3750             \n",
      "  1301     0       950     1/111807       0% 1.013035               62.5000             \n",
      "  1722     0      1000     1/111807       0% 0.815882 0.932509      53.1250      58.3213\n",
      "  1722     0      1000     1/111807       0% 0.815882               53.1250             \n",
      "  1793     0      1050     1/111807       0% 0.877019               56.2500             \n",
      "  1864     0      1100     1/111807       0% 0.764180               75.0000             \n",
      "  1934     0      1150     1/111807       0% 0.867093               56.2500             \n",
      "  2007     0      1200     1/111807       0% 1.168295               25.0000             \n",
      "  2089     0      1250     1/111807       0% 0.768620               68.7500             \n",
      "  2172     0      1300     1/111807       0% 1.076907               37.5000             \n",
      "  2248     0      1350     1/111807       0% 0.868754               50.0000             \n",
      "  2329     0      1400     1/111807       0% 0.941974               50.0000             \n",
      "  2409     0      1450     1/111807       0% 0.839589               62.5000             \n",
      "  2916     0      1500     1/111807       0% 1.009476 0.927442      56.2500      58.3282\n",
      "  2916     0      1500     1/111807       0% 1.009476               56.2500             \n",
      "  3022     0      1550     1/111807       0% 0.707169               65.6250             \n",
      "  3128     0      1600     1/111807       0% 0.839420               62.5000             \n",
      "  3236     0      1650     1/111807       0% 0.779730               68.7500             \n",
      "  3343     0      1700     1/111807       0% 0.879681               59.3750             \n",
      "  3450     0      1750     1/111807       0% 0.982455               59.3750             \n",
      "  3565     0      1800     1/111807       0% 1.032490               43.7500             \n",
      "  3687     0      1850     1/111807       0% 0.879445               59.3750             \n",
      "  3811     0      1900     1/111807       0% 1.001196               59.3750             \n",
      "  3934     0      1950     1/111807       0% 0.722689               81.2500             \n",
      "  4585     0      2000     1/111807       0% 0.862366 0.893639      56.2500      60.5673\n",
      "  4585     0      2000     1/111807       0% 0.862366               56.2500             \n",
      "  4735     0      2050     1/111807       0% 0.908086               53.1250             \n",
      "  4891     0      2100     1/111807       0% 0.732707               71.8750             \n",
      "  5041     0      2150     1/111807       0% 0.683481               68.7500             \n",
      "  5194     0      2200     1/111807       0% 0.621533               71.8750             \n",
      "  5354     0      2250     1/111807       0% 0.746931               68.7500             \n",
      "  5535     0      2300     1/111807       0% 0.838930               65.6250             \n",
      "  5715     0      2350     1/111807       0% 1.178583               46.8750             \n",
      "  5896     0      2400     1/111807       0% 0.813059               62.5000             \n",
      "  6087     0      2450     1/111807       0% 0.927861               68.7500             \n",
      "  6937     0      2500     1/111807       0% 0.848480 0.863674      59.3750      61.3778\n",
      "  6937     0      2500     1/111807       0% 0.848480               59.3750             \n",
      "  7167     0      2550     1/111807       0% 0.831059               62.5000             \n",
      "  7397     0      2600     1/111807       0% 0.828585               56.2500             \n",
      "  7635     0      2650     1/111807       0% 0.784734               65.6250             \n",
      "  7879     0      2700     1/111807       0% 0.952395               56.2500             \n",
      "  8137     0      2750     1/111807       0% 0.806382               68.7500             \n",
      "  8411     0      2800     1/111807       0% 0.885479               56.2500             \n",
      "  8688     0      2850     1/111807       0% 1.062941               43.7500             \n",
      "  8985     0      2900     1/111807       0% 0.773582               68.7500             \n",
      "  9295     0      2950     1/111807       0% 0.800614               65.6250             \n",
      " 10434     0      3000     1/111807       0% 0.913865 0.870797      59.3750      61.1924\n",
      " 10434     0      3000     1/111807       0% 0.913865               59.3750             \n",
      " 10800     0      3050     1/111807       0% 0.676036               75.0000             \n",
      " 11178     0      3100     1/111807       0% 0.978217               53.1250             \n",
      " 11574     0      3150     1/111807       0% 0.908957               62.5000             \n",
      " 11989     0      3200     1/111807       0% 0.820325               65.6250             \n",
      " 12425     0      3250     1/111807       0% 0.809731               68.7500             \n",
      " 12903     0      3300     1/111807       0% 0.903830               56.2500             \n",
      " 13418     0      3350     1/111807       0% 0.693953               59.3750             \n",
      " 13992     0      3400     1/111807       0% 0.843756               68.7500             \n",
      " 14596     0      3450     1/111807       0% 0.933869               59.3750             \n",
      " 16489     1      3500     1/111807       0% 1.127767 0.901861      43.7500      59.7775\n",
      " 16489     1      3500     1/111807       0% 1.127767               43.7500             \n",
      " 16612     1      3550     1/111807       0% 0.842016               56.2500             \n",
      " 16740     1      3600     1/111807       0% 0.713874               68.7500             \n",
      " 16869     1      3650     1/111807       0% 0.824486               68.7500             \n",
      " 16994     1      3700     1/111807       0% 0.977452               50.0000             \n",
      " 17149     1      3750     1/111807       0% 1.016893               46.8750             \n",
      " 17303     1      3800     1/111807       0% 1.068879               56.2500             \n",
      " 17452     1      3850     1/111807       0% 0.881940               56.2500             \n",
      " 17602     1      3900     1/111807       0% 0.837717               65.6250             \n",
      " 17751     1      3950     1/111807       0% 0.819325               68.7500             \n",
      " 19123     1      4000     1/111807       0% 0.604930 0.854449      71.8750      62.1265\n",
      " 19123     1      4000     1/111807       0% 0.604930               71.8750             \n",
      " 19321     1      4050     1/111807       0% 0.630403               75.0000             \n",
      " 19521     1      4100     1/111807       0% 0.699595               65.6250             \n",
      " 19716     1      4150     1/111807       0% 0.716607               71.8750             \n",
      " 19908     1      4200     1/111807       0% 0.687822               75.0000             \n",
      " 20098     1      4250     1/111807       0% 0.992059               53.1250             \n",
      " 20294     1      4300     1/111807       0% 0.905592               62.5000             \n",
      " 20513     1      4350     1/111807       0% 0.748542               68.7500             \n",
      " 20750     1      4400     1/111807       0% 0.647977               71.8750             \n",
      " 20991     1      4450     1/111807       0% 0.844972               56.2500             \n",
      " 22500     1      4500     1/111807       0% 0.714483 0.847693      62.5000      62.3257\n",
      " 22500     1      4500     1/111807       0% 0.714483               62.5000             \n",
      " 22756     1      4550     1/111807       0% 0.636680               75.0000             \n",
      " 23015     1      4600     1/111807       0% 0.940206               56.2500             \n",
      " 23266     1      4650     1/111807       0% 0.859497               59.3750             \n",
      " 23554     1      4700     1/111807       0% 0.774797               62.5000             \n",
      " 23866     1      4750     1/111807       0% 0.711052               71.8750             \n",
      " 24177     1      4800     1/111807       0% 0.646977               78.1250             \n",
      " 24476     1      4850     1/111807       0% 0.770914               62.5000             \n",
      " 24781     1      4900     1/111807       0% 0.659287               87.5000             \n",
      " 25083     1      4950     1/111807       0% 0.872840               62.5000             \n",
      " 26733     1      5000     1/111807       0% 0.539518 0.860380      78.1250      61.5702\n",
      " 26733     1      5000     1/111807       0% 0.539518               78.1250             \n",
      " 27086     1      5050     1/111807       0% 0.912451               62.5000             \n",
      " 27438     1      5100     1/111807       0% 0.584458               78.1250             \n",
      " 27792     1      5150     1/111807       0% 0.636628               71.8750             \n",
      " 28144     1      5200     1/111807       0% 0.678230               75.0000             \n",
      " 28506     1      5250     1/111807       0% 0.592038               78.1250             \n",
      " 28884     1      5300     1/111807       0% 0.931318               56.2500             \n",
      " 29269     1      5350     1/111807       0% 0.678196               68.7500             \n",
      " 29701     1      5400     1/111807       0% 0.650930               65.6250             \n",
      " 30127     1      5450     1/111807       0% 0.721824               68.7500             \n"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/48693587/implement-embedding-dropout-in-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    62     0        50     1/111807       0% 1.360446               37.5000             \n",
      "   125     0       100     1/111807       0% 1.238718               46.8750             \n",
      "   194     0       150     1/111807       0% 1.242219               37.5000             \n",
      "   261     0       200     1/111807       0% 1.173572               43.7500             \n",
      "   333     0       250     1/111807       0% 1.077672               40.6250             \n",
      "   405     0       300     1/111807       0% 1.094793               50.0000             \n",
      "   479     0       350     1/111807       0% 0.979943               62.5000             \n",
      "   552     0       400     1/111807       0% 1.321211               40.6250             \n",
      "   628     0       450     1/111807       0% 1.121003               40.6250             \n",
      "  1051     0       500     1/111807       0% 1.009317 1.151772      43.7500      49.7218\n",
      "  1051     0       500     1/111807       0% 1.009317               43.7500             \n",
      "  1149     0       550     1/111807       0% 0.994759               62.5000             \n",
      "  1239     0       600     1/111807       0% 1.235075               40.6250             \n",
      "  1317     0       650     1/111807       0% 1.061889               53.1250             \n",
      "  1393     0       700     1/111807       0% 1.213376               56.2500             \n",
      "  1470     0       750     1/111807       0% 0.904009               50.0000             \n",
      "  1549     0       800     1/111807       0% 0.982537               53.1250             \n",
      "  1633     0       850     1/111807       0% 0.856570               75.0000             \n",
      "  1723     0       900     1/111807       0% 1.020129               53.1250             \n",
      "  1822     0       950     1/111807       0% 1.031496               50.0000             \n",
      "  2468     0      1000     1/111807       0% 1.036892 1.000690      56.2500      55.6288\n",
      "  2468     0      1000     1/111807       0% 1.036892               56.2500             \n",
      "  2571     0      1050     1/111807       0% 0.968225               43.7500             \n",
      "  2670     0      1100     1/111807       0% 0.873810               59.3750             \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5498\u001b[0m   \"\"\"\n\u001b[0;32m   5499\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5500\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    249\u001b[0m                 mean_loss(batch_train_loss.numpy(),\n\u001b[0;32m    250\u001b[0m                   weights=batch_size.gpu() if use_gpu else batch_size)\n\u001b[1;32m--> 251\u001b[1;33m                 \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_train_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[1;31m#if iterations % params.save_every == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    139\u001b[0m                                     global_step=tf.train.get_global_step())\n\u001b[0;32m    140\u001b[0m         \u001b[1;31m#print (\"Success! Computed gradient :) :)\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m    765\u001b[0m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0;32m    766\u001b[0m         \u001b[0m_default_vspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         output_gradients=output_gradients)\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(vspace, tape, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m     61\u001b[0m   \"\"\"\n\u001b[0;32m     62\u001b[0m   return pywrap_tensorflow.TFE_Py_TapeGradient(\n\u001b[1;32m---> 63\u001b[1;33m       tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgrad_fn\u001b[1;34m(*orig_outputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0morig_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     result = _magic_gradient_function(op_name, attrs, num_inputs,\n\u001b[1;32m--> 147\u001b[1;33m                                       op_inputs, op_outputs, orig_outputs)\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_tracing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m       print(\"Gradient for\", op_name, \"inputs\", op_inputs, \"output_grads\",\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_magic_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_RealDivGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    929\u001b[0m   \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m   \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m   \u001b[0msx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m   \u001b[0msy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m   \u001b[0mrx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_gradient_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, name, out_type)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m   \"\"\"\n\u001b[1;32m--> 285\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[1;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, out_type, name)\u001b[0m\n\u001b[0;32m   8360\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   8361\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Shape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8362\u001b[1;33m         _ctx._post_execution_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[0;32m   8363\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8364\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    65     0        50     1/111807       0% 1.325724               40.6250             \n",
      "   130     0       100     1/111807       0% 1.130076               46.8750             \n",
      "   198     0       150     1/111807       0% 1.231451               37.5000             \n",
      "   263     0       200     1/111807       0% 1.141092               43.7500             \n",
      "   337     0       250     1/111807       0% 0.994522               65.6250             \n",
      "   409     0       300     1/111807       0% 1.153162               50.0000             \n",
      "   479     0       350     1/111807       0% 0.945205               65.6250             \n",
      "   544     0       400     1/111807       0% 1.356824               34.3750             \n",
      "   615     0       450     1/111807       0% 1.134035               46.8750             \n",
      "   991     0       500     1/111807       0% 1.033407 1.103765      50.0000      51.0887\n",
      "   991     0       500     1/111807       0% 1.033407               50.0000             \n",
      "  1064     0       550     1/111807       0% 1.026398               56.2500             \n",
      "  1136     0       600     1/111807       0% 1.133685               46.8750             \n",
      "  1210     0       650     1/111807       0% 1.000165               56.2500             \n",
      "  1284     0       700     1/111807       0% 1.227050               37.5000             \n",
      "  1352     0       750     1/111807       0% 0.938555               53.1250             \n",
      "  1426     0       800     1/111807       0% 0.969874               59.3750             \n",
      "  1501     0       850     1/111807       0% 0.798843               65.6250             \n",
      "  1581     0       900     1/111807       0% 0.978927               56.2500             \n",
      "  1665     0       950     1/111807       0% 1.020303               59.3750             \n",
      "  2103     0      1000     1/111807       0% 0.994448 1.004096      62.5000      55.1824\n",
      "  2103     0      1000     1/111807       0% 0.994448               62.5000             \n",
      "  2187     0      1050     1/111807       0% 0.956878               59.3750             \n",
      "  2270     0      1100     1/111807       0% 0.852986               68.7500             \n",
      "  2350     0      1150     1/111807       0% 0.881425               53.1250             \n",
      "  2437     0      1200     1/111807       0% 1.197100               28.1250             \n",
      "  2531     0      1250     1/111807       0% 0.860474               62.5000             \n",
      "  2628     0      1300     1/111807       0% 0.947627               53.1250             \n",
      "  2716     0      1350     1/111807       0% 0.783981               62.5000             \n",
      "  2808     0      1400     1/111807       0% 1.135440               37.5000             \n",
      "  2899     0      1450     1/111807       0% 0.882543               59.3750             \n",
      "  3398     0      1500     1/111807       0% 0.934867 1.006675      50.0000      55.1068\n",
      "  3398     0      1500     1/111807       0% 0.934867               50.0000             \n",
      "  3518     0      1550     1/111807       0% 0.943461               62.5000             \n",
      "  3635     0      1600     1/111807       0% 0.828945               50.0000             \n",
      "  3754     0      1650     1/111807       0% 0.924896               65.6250             \n",
      "  3871     0      1700     1/111807       0% 1.124577               46.8750             \n",
      "  3988     0      1750     1/111807       0% 1.134018               50.0000             \n",
      "  4115     0      1800     1/111807       0% 1.269536               43.7500             \n",
      "  4245     0      1850     1/111807       0% 0.905172               62.5000             \n",
      "  4381     0      1900     1/111807       0% 0.981926               62.5000             \n",
      "  4517     0      1950     1/111807       0% 0.881553               59.3750             \n",
      "  5157     0      2000     1/111807       0% 0.926860 0.962022      59.3750      57.2086\n",
      "  5157     0      2000     1/111807       0% 0.926860               59.3750             \n",
      "  5321     0      2050     1/111807       0% 0.924310               53.1250             \n",
      "  5489     0      2100     1/111807       0% 0.865773               62.5000             \n",
      "  5702     0      2150     1/111807       0% 0.766962               65.6250             \n",
      "  5962     0      2200     1/111807       0% 0.883841               62.5000             \n",
      "  6213     0      2250     1/111807       0% 0.850255               56.2500             \n",
      "  6471     0      2300     1/111807       0% 0.932777               62.5000             \n",
      "  6744     0      2350     1/111807       0% 1.257385               53.1250             \n",
      "  7035     0      2400     1/111807       0% 0.959714               59.3750             \n",
      "  7328     0      2450     1/111807       0% 0.965088               65.6250             \n",
      " 11175     0      2500     1/111807       0% 1.059618 0.922921      56.2500      58.6785\n",
      " 11175     0      2500     1/111807       0% 1.059618               56.2500             \n",
      " 11436     0      2550     1/111807       0% 0.924756               56.2500             \n",
      " 11686     0      2600     1/111807       0% 0.839046               59.3750             \n",
      " 11939     0      2650     1/111807       0% 0.832972               75.0000             \n",
      " 12212     0      2700     1/111807       0% 1.059577               50.0000             \n",
      " 12492     0      2750     1/111807       0% 1.039869               53.1250             \n",
      " 12778     0      2800     1/111807       0% 0.819635               56.2500             \n",
      " 13075     0      2850     1/111807       0% 1.244863               53.1250             \n",
      " 13393     0      2900     1/111807       0% 0.964952               62.5000             \n",
      " 13715     0      2950     1/111807       0% 0.816638               62.5000             \n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[150,750] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5498\u001b[0m   \"\"\"\n\u001b[0;32m   5499\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5500\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m                 \u001b[0miterations\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m                 \u001b[0mbatch_train_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_train_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                 mean_loss(batch_train_loss.numpy(),\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;31m#reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;31m#loss1 = loss + reg_losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         self._optimizer.apply_gradients(zip(gradients, self._model.variables),\n\u001b[0;32m    139\u001b[0m                                     global_step=tf.train.get_global_step())\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m    765\u001b[0m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0;32m    766\u001b[0m         \u001b[0m_default_vspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         output_gradients=output_gradients)\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(vspace, tape, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m     61\u001b[0m   \"\"\"\n\u001b[0;32m     62\u001b[0m   return pywrap_tensorflow.TFE_Py_TapeGradient(\n\u001b[1;32m---> 63\u001b[1;33m       tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgrad_fn\u001b[1;34m(*orig_outputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0morig_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     result = _magic_gradient_function(op_name, attrs, num_inputs,\n\u001b[1;32m--> 147\u001b[1;33m                                       op_inputs, op_outputs, orig_outputs)\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_tracing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m       print(\"Gradient for\", op_name, \"inputs\", op_inputs, \"output_grads\",\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_magic_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1045\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   4591\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4592\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4593\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[150,750] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    59     0        50     1/111807       0% 1.332807               40.6250             \n",
      "   117     0       100     1/111807       0% 1.185076               43.7500             \n",
      "   187     0       150     1/111807       0% 1.249512               40.6250             \n",
      "   268     0       200     1/111807       0% 1.104330               43.7500             \n",
      "   355     0       250     1/111807       0% 1.020807               43.7500             \n",
      "   435     0       300     1/111807       0% 1.139809               50.0000             \n",
      "   513     0       350     1/111807       0% 0.981352               56.2500             \n",
      "   584     0       400     1/111807       0% 1.293514               40.6250             \n",
      "   657     0       450     1/111807       0% 1.107861               46.8750             \n",
      "  1079     0       500     1/111807       0% 1.007433 1.099918      46.8750      51.0818\n",
      "  1079     0       500     1/111807       0% 1.007433               46.8750             \n",
      "  1165     0       550     1/111807       0% 0.968710               56.2500             \n",
      "  1256     0       600     1/111807       0% 1.151357               53.1250             \n",
      "  1335     0       650     1/111807       0% 0.989752               59.3750             \n",
      "  1413     0       700     1/111807       0% 1.203530               46.8750             \n",
      "  1489     0       750     1/111807       0% 0.932848               59.3750             \n",
      "  1570     0       800     1/111807       0% 0.971089               56.2500             \n",
      "  1652     0       850     1/111807       0% 0.812226               68.7500             \n",
      "  1737     0       900     1/111807       0% 0.977381               53.1250             \n",
      "  1825     0       950     1/111807       0% 1.061873               50.0000             \n",
      "  2380     0      1000     1/111807       0% 0.994417 0.993410      56.2500      55.9997\n",
      "  2380     0      1000     1/111807       0% 0.994417               56.2500             \n",
      "  2475     0      1050     1/111807       0% 0.977390               50.0000             \n",
      "  2575     0      1100     1/111807       0% 0.882454               65.6250             \n",
      "  2673     0      1150     1/111807       0% 0.918055               53.1250             \n",
      "  2776     0      1200     1/111807       0% 1.238489               28.1250             \n",
      "  2892     0      1250     1/111807       0% 0.909713               56.2500             \n",
      "  3010     0      1300     1/111807       0% 0.957889               56.2500             \n",
      "  3123     0      1350     1/111807       0% 0.778798               59.3750             \n",
      "  3242     0      1400     1/111807       0% 1.163645               40.6250             \n",
      "  3357     0      1450     1/111807       0% 0.954040               56.2500             \n",
      "  4117     0      1500     1/111807       0% 0.899500 1.048795      53.1250      54.0284\n",
      "  4117     0      1500     1/111807       0% 0.899500               53.1250             \n",
      "  4285     0      1550     1/111807       0% 1.042873               56.2500             \n",
      "  4448     0      1600     1/111807       0% 0.904862               50.0000             \n",
      "  4618     0      1650     1/111807       0% 0.978502               56.2500             \n",
      "  4783     0      1700     1/111807       0% 1.129337               53.1250             \n",
      "  4956     0      1750     1/111807       0% 1.114366               50.0000             \n",
      "  5139     0      1800     1/111807       0% 1.263404               53.1250             \n",
      "  5325     0      1850     1/111807       0% 0.983240               62.5000             \n",
      "  5524     0      1900     1/111807       0% 1.048218               62.5000             \n",
      "  5705     0      1950     1/111807       0% 0.957453               53.1250             \n",
      "  6362     0      2000     1/111807       0% 0.915382 0.943335      59.3750      57.9092\n",
      "  6362     0      2000     1/111807       0% 0.915382               59.3750             \n",
      "  6536     0      2050     1/111807       0% 0.970218               50.0000             \n",
      "  6707     0      2100     1/111807       0% 0.920390               62.5000             \n",
      "  6876     0      2150     1/111807       0% 0.739617               65.6250             \n",
      "  7054     0      2200     1/111807       0% 0.821234               68.7500             \n"
     ]
    }
   ],
   "source": [
    " % run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    65     0        50     1/111807       0% 1.333061               37.5000             \n",
      "   130     0       100     1/111807       0% 1.183811               37.5000             \n",
      "   201     0       150     1/111807       0% 1.247881               40.6250             \n",
      "   268     0       200     1/111807       0% 1.108178               43.7500             \n",
      "   600     0       250     1/111807       0% 1.016599               46.8750             \n",
      "   668     0       300     1/111807       0% 1.144982               50.0000             \n",
      "   738     0       350     1/111807       0% 0.980765               59.3750             \n",
      "   803     0       400     1/111807       0% 1.303097               40.6250             \n",
      "   873     0       450     1/111807       0% 1.104563               46.8750             \n",
      "  1293     0       500     1/111807       0% 0.997709 1.137476      46.8750      50.2507\n",
      "  1299     0       500     1/111807       0% 0.997709               46.8750             \n",
      "  1388     0       550     1/111807       0% 0.970128               56.2500             \n",
      "  1466     0       600     1/111807       0% 1.144825               50.0000             \n",
      "  1541     0       650     1/111807       0% 0.988629               62.5000             \n",
      "  1615     0       700     1/111807       0% 1.207198               46.8750             \n",
      "  1690     0       750     1/111807       0% 0.935975               59.3750             \n",
      "  1768     0       800     1/111807       0% 0.948231               62.5000             \n",
      "  1847     0       850     1/111807       0% 0.807644               71.8750             \n",
      "  1933     0       900     1/111807       0% 0.985679               53.1250             \n",
      "  2021     0       950     1/111807       0% 1.063571               50.0000             \n",
      "  2536     0      1000     1/111807       0% 1.006817 0.994601      56.2500      55.8349\n",
      "  2536     0      1000     1/111807       0% 1.006817               56.2500             \n",
      "  2630     0      1050     1/111807       0% 0.983745               43.7500             \n",
      "  2723     0      1100     1/111807       0% 0.878384               65.6250             \n",
      "  2815     0      1150     1/111807       0% 0.911608               53.1250             \n",
      "  2913     0      1200     1/111807       0% 1.232265               28.1250             \n",
      "  3022     0      1250     1/111807       0% 0.927224               56.2500             \n",
      "  3137     0      1300     1/111807       0% 0.962744               53.1250             \n",
      "  3236     0      1350     1/111807       0% 0.812532               59.3750             \n",
      "  3344     0      1400     1/111807       0% 1.156582               40.6250             \n",
      "  3454     0      1450     1/111807       0% 0.947974               59.3750             \n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3193,216,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Transpose] name: thanos/spinn/transpose/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5498\u001b[0m   \"\"\"\n\u001b[0;32m   5499\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5500\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    242\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                     dev_loss, dev_frac_correct = _evaluate_on_dataset(\n\u001b[1;32m--> 244\u001b[1;33m               val_dataset, trainer, use_gpu)\n\u001b[0m\u001b[0;32m    245\u001b[0m                     print(dev_log_template.format(\n\u001b[0;32m    246\u001b[0m                           \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36m_evaluate_on_dataset\u001b[1;34m(val_dataset, trainer, use_gpu)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \"\"\"\n\u001b[0;32m    313\u001b[0m     \u001b[1;31m# Actually call the layer (optionally building it).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_uses_inputs_arg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m             raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         sentence_level_outputs = self.sentence_encoder(sentence_embeddings, transitions,\n\u001b[1;32m---> 72\u001b[1;33m                            training = is_training)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m#generate document level embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \"\"\"\n\u001b[0;32m    313\u001b[0m     \u001b[1;31m# Actually call the layer (optionally building it).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_uses_inputs_arg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m             raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\SPINN.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, buffers, transitions, training)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;31m# items in a stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     splitted = tf.split(\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_proj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         max_sequence_len * batch_size, axis=0)\n\u001b[0;32m    173\u001b[0m     buffers = [splitted[k:k + max_sequence_len]\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[0;32m   1482\u001b[0m           \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranspose_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(x, perm, name)\u001b[0m\n\u001b[0;32m  10518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10519\u001b[0m       return transpose_eager_fallback(\n\u001b[1;32m> 10520\u001b[1;33m           x, perm, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m  10521\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10522\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose_eager_fallback\u001b[1;34m(x, perm, name, ctx)\u001b[0m\n\u001b[0;32m  10537\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tperm\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_Tperm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10538\u001b[0m   _result = _execute.execute(b\"Transpose\", 1, inputs=_inputs_flat,\n\u001b[1;32m> 10539\u001b[1;33m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[0;32m  10540\u001b[0m   _execute.record_gradient(\n\u001b[0;32m  10541\u001b[0m       \"Transpose\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\latest\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3193,216,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Transpose] name: thanos/spinn/transpose/"
     ]
    }
   ],
   "source": [
    " % run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    59     0        50     1/111807       0% 1.331344               37.5000             \n",
      "   118     0       100     1/111807       0% 1.183611               43.7500             \n",
      "   181     0       150     1/111807       0% 1.250331               40.6250             \n",
      "   241     0       200     1/111807       0% 1.158607               46.8750             \n",
      "   310     0       250     1/111807       0% 1.008730               50.0000             \n",
      "   376     0       300     1/111807       0% 1.151758               50.0000             \n",
      "   441     0       350     1/111807       0% 0.971759               59.3750             \n",
      "   506     0       400     1/111807       0% 1.319272               46.8750             \n",
      "   575     0       450     1/111807       0% 1.114181               50.0000             \n",
      "   948     0       500     1/111807       0% 1.010440 1.104338      50.0000      51.0749\n",
      "   948     0       500     1/111807       0% 1.010440               50.0000             \n",
      "  1028     0       550     1/111807       0% 0.971401               56.2500             \n",
      "  1114     0       600     1/111807       0% 1.163466               50.0000             \n",
      "  1188     0       650     1/111807       0% 0.994453               62.5000             \n",
      "  1267     0       700     1/111807       0% 1.199455               43.7500             \n",
      "  1352     0       750     1/111807       0% 0.932055               56.2500             \n",
      "  1428     0       800     1/111807       0% 0.952215               65.6250             \n",
      "  1510     0       850     1/111807       0% 0.811938               75.0000             \n",
      "  1599     0       900     1/111807       0% 0.984232               53.1250             \n",
      "  1696     0       950     1/111807       0% 1.055512               50.0000             \n",
      "  2197     0      1000     1/111807       0% 0.993950 0.987045      56.2500      56.1920\n",
      "  2197     0      1000     1/111807       0% 0.993950               56.2500             \n",
      "  2282     0      1050     1/111807       0% 0.973592               46.8750             \n",
      "  2370     0      1100     1/111807       0% 0.882766               65.6250             \n",
      "  2453     0      1150     1/111807       0% 0.908740               53.1250             \n",
      "  2545     0      1200     1/111807       0% 1.234029               25.0000             \n",
      "  2643     0      1250     1/111807       0% 0.942933               56.2500             \n",
      "  2742     0      1300     1/111807       0% 0.955815               59.3750             \n",
      "  2833     0      1350     1/111807       0% 0.798233               62.5000             \n",
      "  2930     0      1400     1/111807       0% 1.155799               40.6250             \n",
      "  3025     0      1450     1/111807       0% 0.974174               56.2500             \n",
      "  3547     0      1500     1/111807       0% 0.922769 1.047983      50.0000      54.0422\n",
      "  3547     0      1500     1/111807       0% 0.922769               50.0000             \n",
      "  3671     0      1550     1/111807       0% 1.011376               56.2500             \n",
      "  3793     0      1600     1/111807       0% 0.887074               56.2500             \n",
      "  3916     0      1650     1/111807       0% 0.998925               56.2500             \n",
      "  4038     0      1700     1/111807       0% 1.127862               50.0000             \n",
      "  4159     0      1750     1/111807       0% 1.117009               53.1250             \n",
      "  4288     0      1800     1/111807       0% 1.232087               53.1250             \n",
      "  4437     0      1850     1/111807       0% 0.962738               59.3750             \n",
      "  4607     0      1900     1/111807       0% 1.026537               59.3750             \n",
      "  4765     0      1950     1/111807       0% 0.976030               46.8750             \n",
      "  5517     0      2000     1/111807       0% 0.911142 0.944376      62.5000      57.8749\n",
      "  5517     0      2000     1/111807       0% 0.911142               62.5000             \n",
      "  5695     0      2050     1/111807       0% 0.985368               53.1250             \n",
      "  5877     0      2100     1/111807       0% 0.911145               59.3750             \n",
      "  6050     0      2150     1/111807       0% 0.740567               65.6250             \n",
      "  6225     0      2200     1/111807       0% 0.821703               65.6250             \n",
      "  6411     0      2250     1/111807       0% 0.844625               59.3750             \n",
      "  6611     0      2300     1/111807       0% 1.042723               53.1250             \n",
      "  6815     0      2350     1/111807       0% 1.214440               46.8750             \n",
      "  7021     0      2400     1/111807       0% 0.952828               68.7500             \n",
      "  7243     0      2450     1/111807       0% 1.014743               68.7500             \n",
      "  8160     0      2500     1/111807       0% 1.104967 0.924505      53.1250      58.6304\n",
      "  8160     0      2500     1/111807       0% 1.104967               53.1250             \n",
      "  8416     0      2550     1/111807       0% 1.008815               53.1250             \n",
      "  8671     0      2600     1/111807       0% 0.929885               59.3750             \n",
      "  8935     0      2650     1/111807       0% 0.789095               75.0000             \n",
      "  9228     0      2700     1/111807       0% 1.124155               37.5000             \n",
      "  9523     0      2750     1/111807       0% 0.977909               56.2500             \n",
      "  9819     0      2800     1/111807       0% 0.809719               59.3750             \n",
      " 10119     0      2850     1/111807       0% 1.193345               53.1250             \n",
      " 10435     0      2900     1/111807       0% 1.007935               62.5000             \n"
     ]
    }
   ],
   "source": [
    " % run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    47     0        50     1/111807       0% 0.949516               50.0000             \n",
      "    97     0       100     1/111807       0% 0.748508               59.3750             \n",
      "   153     0       150     1/111807       0% 0.780258               75.0000             \n",
      "   199     0       200     1/111807       0% 0.811868               65.6250             \n",
      "   252     0       250     1/111807       0% 0.719613               62.5000             \n",
      "   301     0       300     1/111807       0% 0.935248               59.3750             \n",
      "   352     0       350     1/111807       0% 0.557297               81.2500             \n",
      "   400     0       400     1/111807       0% 0.906406               68.7500             \n",
      "   457     0       450     1/111807       0% 0.812205               62.5000             \n",
      "   827     0       500     1/111807       0% 0.604728 1.317585      78.1250      50.8757\n",
      "   891     0       550     1/111807       0% 0.955131               56.2500             \n",
      "   956     0       600     1/111807       0% 1.003520               56.2500             \n",
      "  1014     0       650     1/111807       0% 0.952410               59.3750             \n",
      "  1073     0       700     1/111807       0% 1.156027               56.2500             \n",
      "  1130     0       750     1/111807       0% 0.833276               65.6250             \n",
      "  1194     0       800     1/111807       0% 0.949542               65.6250             \n",
      "  1261     0       850     1/111807       0% 0.839845               68.7500             \n",
      "  1330     0       900     1/111807       0% 0.926956               59.3750             \n",
      "  1397     0       950     1/111807       0% 1.039136               53.1250             \n",
      "  1829     0      1000     1/111807       0% 0.892919 0.933211      62.5000      58.6029\n",
      "  1917     0      1050     1/111807       0% 0.929217               53.1250             \n",
      "  1997     0      1100     1/111807       0% 0.854994               75.0000             \n",
      "  2069     0      1150     1/111807       0% 0.917681               65.6250             \n",
      "  2147     0      1200     1/111807       0% 1.299811               31.2500             \n",
      "  2229     0      1250     1/111807       0% 1.038761               50.0000             \n",
      "  2311     0      1300     1/111807       0% 1.053082               43.7500             \n",
      "  2388     0      1350     1/111807       0% 0.837544               59.3750             \n",
      "  2468     0      1400     1/111807       0% 0.988266               50.0000             \n",
      "  2547     0      1450     1/111807       0% 0.864297               62.5000             \n",
      "  3017     0      1500     1/111807       0% 0.962683 0.914880      56.2500      59.2760\n",
      "  3115     0      1550     1/111807       0% 0.771310               75.0000             \n",
      "  3209     0      1600     1/111807       0% 0.992238               59.3750             \n",
      "  3308     0      1650     1/111807       0% 0.775920               71.8750             \n",
      "  3407     0      1700     1/111807       0% 0.984203               62.5000             \n",
      "  3503     0      1750     1/111807       0% 1.005532               53.1250             \n",
      "  3627     0      1800     1/111807       0% 1.047367               50.0000             \n",
      "  3745     0      1850     1/111807       0% 0.847948               65.6250             \n",
      "  3867     0      1900     1/111807       0% 0.970852               65.6250             \n",
      "  4006     0      1950     1/111807       0% 0.832692               56.2500             \n",
      "  4656     0      2000     1/111807       0% 0.975783 0.880058      56.2500      61.1787\n",
      "  4834     0      2050     1/111807       0% 0.959673               53.1250             \n",
      "  4988     0      2100     1/111807       0% 0.802252               56.2500             \n",
      "  5158     0      2150     1/111807       0% 0.761276               65.6250             \n",
      "  5305     0      2200     1/111807       0% 0.704598               62.5000             \n",
      "  5467     0      2250     1/111807       0% 0.683058               71.8750             \n",
      "  5643     0      2300     1/111807       0% 0.995368               53.1250             \n",
      "  5825     0      2350     1/111807       0% 1.176551               53.1250             \n",
      "  6008     0      2400     1/111807       0% 0.978445               59.3750             \n",
      "  6200     0      2450     1/111807       0% 0.951436               56.2500             \n",
      "  6997     0      2500     1/111807       0% 1.012288 0.865579      56.2500      61.5290\n",
      "  7218     0      2550     1/111807       0% 0.887679               62.5000             \n",
      "  7437     0      2600     1/111807       0% 0.834020               62.5000             \n",
      "  7664     0      2650     1/111807       0% 0.745305               68.7500             \n",
      "  7921     0      2700     1/111807       0% 0.967291               65.6250             \n",
      "  8184     0      2750     1/111807       0% 0.887814               56.2500             \n",
      "  8448     0      2800     1/111807       0% 0.835745               59.3750             \n",
      "  8725     0      2850     1/111807       0% 1.080692               46.8750             \n",
      "  9017     0      2900     1/111807       0% 0.835810               71.8750             \n",
      "  9330     0      2950     1/111807       0% 0.786768               65.6250             \n",
      " 10446     0      3000     1/111807       0% 1.187893 0.872236      53.1250      61.5083\n",
      " 10917     0      3050     1/111807       0% 0.997044               59.3750             \n",
      " 11277     0      3100     1/111807       0% 0.900428               59.3750             \n",
      " 11655     0      3150     1/111807       0% 1.031400               56.2500             \n",
      " 12058     0      3200     1/111807       0% 0.762431               75.0000             \n",
      " 12508     0      3250     1/111807       0% 0.835200               59.3750             \n",
      " 12987     0      3300     1/111807       0% 0.838856               59.3750             \n",
      " 13494     0      3350     1/111807       0% 0.881035               56.2500             \n",
      " 14042     0      3400     1/111807       0% 0.775109               78.1250             \n",
      " 14643     0      3450     1/111807       0% 1.048021               62.5000             \n",
      " 16543     1      3500     1/111807       0% 0.964235 0.880944      59.3750      61.0413\n",
      " 16675     1      3550     1/111807       0% 0.794427               71.8750             \n",
      " 16816     1      3600     1/111807       0% 0.792984               62.5000             \n",
      " 16955     1      3650     1/111807       0% 0.858992               68.7500             \n",
      " 17089     1      3700     1/111807       0% 1.176815               46.8750             \n",
      " 17255     1      3750     1/111807       0% 0.892973               62.5000             \n",
      " 17417     1      3800     1/111807       0% 1.071754               53.1250             \n",
      " 17574     1      3850     1/111807       0% 0.721995               65.6250             \n",
      " 17733     1      3900     1/111807       0% 0.804366               56.2500             \n",
      " 17890     1      3950     1/111807       0% 0.796070               75.0000             \n",
      " 19306     1      4000     1/111807       0% 0.706538 0.887943      75.0000      60.4231\n",
      " 19505     1      4050     1/111807       0% 0.833085               65.6250             \n",
      " 19707     1      4100     1/111807       0% 0.855806               65.6250             \n",
      " 19905     1      4150     1/111807       0% 0.787736               65.6250             \n",
      " 20105     1      4200     1/111807       0% 0.719926               71.8750             \n",
      " 20299     1      4250     1/111807       0% 0.857114               53.1250             \n",
      " 20494     1      4300     1/111807       0% 0.945863               59.3750             \n",
      " 20705     1      4350     1/111807       0% 0.831226               68.7500             \n",
      " 20932     1      4400     1/111807       0% 0.869019               68.7500             \n",
      " 21162     1      4450     1/111807       0% 0.798877               62.5000             \n",
      " 22635     1      4500     1/111807       0% 0.776927 0.857958      56.2500      61.7487\n",
      " 22873     1      4550     1/111807       0% 0.781821               68.7500             \n",
      " 23110     1      4600     1/111807       0% 0.866460               62.5000             \n",
      " 23343     1      4650     1/111807       0% 0.795986               62.5000             \n",
      " 23599     1      4700     1/111807       0% 0.921113               62.5000             \n",
      " 23877     1      4750     1/111807       0% 0.946152               62.5000             \n",
      " 24155     1      4800     1/111807       0% 0.835954               68.7500             \n",
      " 24422     1      4850     1/111807       0% 1.029179               53.1250             \n",
      " 24694     1      4900     1/111807       0% 0.727495               78.1250             \n",
      " 24960     1      4950     1/111807       0% 0.933543               53.1250             \n",
      " 26535     1      5000     1/111807       0% 0.823740 0.857417      62.5000      62.1677\n",
      " 26840     1      5050     1/111807       0% 1.030664               71.8750             \n",
      " 27143     1      5100     1/111807       0% 0.776112               75.0000             \n",
      " 27449     1      5150     1/111807       0% 0.734439               65.6250             \n",
      " 27753     1      5200     1/111807       0% 0.743368               71.8750             \n",
      " 28053     1      5250     1/111807       0% 0.793945               65.6250             \n",
      " 28381     1      5300     1/111807       0% 0.887288               62.5000             \n",
      " 28714     1      5350     1/111807       0% 0.743967               71.8750             \n",
      " 29060     1      5400     1/111807       0% 0.749004               65.6250             \n",
      " 29394     1      5450     1/111807       0% 0.754105               68.7500             \n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3193,216,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Transpose] name: thanos/spinn/transpose/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5285\u001b[0m   \"\"\"\n\u001b[0;32m   5286\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    242\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                     dev_loss, dev_frac_correct = _evaluate_on_dataset(\n\u001b[1;32m--> 244\u001b[1;33m               val_dataset, trainer, use_gpu)\n\u001b[0m\u001b[0;32m    245\u001b[0m                     print(dev_log_template.format(\n\u001b[0;32m    246\u001b[0m                           \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36m_evaluate_on_dataset\u001b[1;34m(val_dataset, trainer, use_gpu)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         sentence_level_outputs = self.sentence_encoder(sentence_embeddings, transitions,\n\u001b[1;32m---> 72\u001b[1;33m                            training = is_training)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m#generate document level embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\SPINN.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, buffers, transitions, training)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;31m# items in a stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     splitted = tf.split(\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_proj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         max_sequence_len * batch_size, axis=0)\n\u001b[0;32m    173\u001b[0m     buffers = [splitted[k:k + max_sequence_len]\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[0;32m   1407\u001b[0m           \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranspose_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(x, perm, name)\u001b[0m\n\u001b[0;32m  10625\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10626\u001b[0m       return transpose_eager_fallback(\n\u001b[1;32m> 10627\u001b[1;33m           x, perm, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m  10628\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10629\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose_eager_fallback\u001b[1;34m(x, perm, name, ctx)\u001b[0m\n\u001b[0;32m  10644\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tperm\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_Tperm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10645\u001b[0m   _result = _execute.execute(b\"Transpose\", 1, inputs=_inputs_flat,\n\u001b[1;32m> 10646\u001b[1;33m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[0;32m  10647\u001b[0m   _execute.record_gradient(\n\u001b[0;32m  10648\u001b[0m       \"Transpose\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3193,216,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Transpose] name: thanos/spinn/transpose/"
     ]
    }
   ],
   "source": [
    " % run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "   793     0       500     1/111807       0% 1.032105 1.078594      56.2500      51.5489\n",
      "  1741     0      1000     1/111807       0% 0.807993 0.936875      68.7500      58.3076\n",
      "  2931     0      1500     1/111807       0% 1.032041 0.937458      59.3750      58.1565\n",
      " 34929     0      2000     1/111807       0% 0.872456 0.907848      56.2500      59.1318\n",
      " 37117     0      2500     1/111807       0% 1.038993 0.872771      46.8750      61.2611\n",
      " 40321     0      3000     1/111807       0% 1.087869 0.875854      43.7500      60.9176\n",
      " 45860     1      3500     1/111807       0% 0.899810 0.863441      56.2500      61.3298\n",
      " 48246     1      4000     1/111807       0% 0.730621 0.865151      65.6250      61.7075\n",
      " 51338     1      4500     1/111807       0% 0.727430 0.845801      65.6250      62.2776\n",
      " 55063     1      5000     1/111807       0% 0.532114 0.847290      81.2500      62.1609\n",
      " 59603     1      5500     1/111807       0% 0.889049 0.861727      65.6250      61.3710\n",
      " 65680     1      6000     1/111807       0% 0.592125 0.830897      81.2500      62.9920\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[150,750] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5285\u001b[0m   \"\"\"\n\u001b[0;32m   5286\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[0miterations\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m                 \u001b[0mbatch_train_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_train_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m                 mean_loss(batch_train_loss.numpy(),\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         self._optimizer.apply_gradients(zip(gradients, self._model.variables),\n\u001b[0;32m    126\u001b[0m                                     global_step=tf.train.get_global_step())     \n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m    856\u001b[0m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0;32m    857\u001b[0m         \u001b[0m_default_vspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m         output_gradients=output_gradients)\n\u001b[0m\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(vspace, tape, target, sources, output_gradients)\u001b[0m\n\u001b[0;32m     61\u001b[0m   \"\"\"\n\u001b[0;32m     62\u001b[0m   return pywrap_tensorflow.TFE_Py_TapeGradient(\n\u001b[1;32m---> 63\u001b[1;33m       tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1077\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   4774\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4775\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4776\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[150,750] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "% run train.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    93     0       100     1/111807       0% 1.207205               34.3750             \n",
      "   187     0       200     1/111807       0% 1.128200               50.0000             \n",
      "   294     0       300     1/111807       0% 1.234668               46.8750             \n",
      "   398     0       400     1/111807       0% 1.288612               31.2500             \n",
      "   822     0       500     1/111807       0% 1.093820 1.088475      50.0000      52.0434\n",
      "   958     0       600     1/111807       0% 1.160606               34.3750             \n",
      "  1085     0       700     1/111807       0% 1.208711               50.0000             \n",
      "  1214     0       800     1/111807       0% 0.971802               62.5000             \n",
      "  1354     0       900     1/111807       0% 1.110901               50.0000             \n",
      "  1917     0      1000     1/111807       0% 0.827912 0.944928      59.3750      57.6482\n",
      "  2075     0      1100     1/111807       0% 0.959335               71.8750             \n",
      "  2243     0      1200     1/111807       0% 1.248748               43.7500             \n",
      "  2436     0      1300     1/111807       0% 0.944673               43.7500             \n",
      "  2618     0      1400     1/111807       0% 1.066203               46.8750             \n",
      "  3292     0      1500     1/111807       0% 1.053256 0.945901      59.3750      58.0740\n",
      "  3532     0      1600     1/111807       0% 0.887579               68.7500             \n",
      "  3765     0      1700     1/111807       0% 0.933387               56.2500             \n",
      "  3997     0      1800     1/111807       0% 1.221609               37.5000             \n",
      "  4234     0      1900     1/111807       0% 0.972874               59.3750             \n",
      "  4912     0      2000     1/111807       0% 0.956133 0.914037      53.1250      59.0356\n",
      "  5211     0      2100     1/111807       0% 0.862216               68.7500             \n",
      "  5506     0      2200     1/111807       0% 0.688711               71.8750             \n",
      "  5822     0      2300     1/111807       0% 0.992149               65.6250             \n",
      "  6143     0      2400     1/111807       0% 0.931152               65.6250             \n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Split] name: split",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5285\u001b[0m   \"\"\"\n\u001b[0;32m   5286\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    242\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                     dev_loss, dev_frac_correct = _evaluate_on_dataset(\n\u001b[1;32m--> 244\u001b[1;33m               val_dataset, trainer, use_gpu)\n\u001b[0m\u001b[0;32m    245\u001b[0m                     print(dev_log_template.format(\n\u001b[0;32m    246\u001b[0m                           \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36m_evaluate_on_dataset\u001b[1;34m(val_dataset, trainer, use_gpu)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         sentence_level_outputs = self.sentence_encoder(sentence_embeddings, transitions,\n\u001b[1;32m---> 72\u001b[1;33m                            training = is_training)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m#generate document level embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\SPINN.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, buffers, transitions, training)\u001b[0m\n\u001b[0;32m    170\u001b[0m     splitted = tf.split(\n\u001b[0;32m    171\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_proj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         max_sequence_len * batch_size, axis=0)\n\u001b[0m\u001b[0;32m    173\u001b[0m     buffers = [splitted[k:k + max_sequence_len]\n\u001b[0;32m    174\u001b[0m                for k in xrange(0, len(splitted), max_sequence_len)]\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(value, num_or_size_splits, axis, num, name)\u001b[0m\n\u001b[0;32m   1314\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msize_splits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msize_splits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m     return gen_array_ops.split(\n\u001b[1;32m-> 1316\u001b[1;33m         axis=axis, num_split=num_or_size_splits, value=value, name=name)\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(axis, value, num_split, name)\u001b[0m\n\u001b[0;32m   9616\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9617\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9618\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   9619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Split] name: split"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    97     0       100     1/111807       0% 1.019094               53.1250             \n",
      "   207     0       200     1/111807       0% 1.026429               56.2500             \n",
      "   318     0       300     1/111807       0% 1.076289               53.1250             \n",
      "   427     0       400     1/111807       0% 1.016116               59.3750             \n",
      "   845     0       500     1/111807       0% 0.847657 0.921221      62.5000      59.2417\n",
      "   980     0       600     1/111807       0% 0.883368               59.3750             \n",
      "  1102     0       700     1/111807       0% 1.019970               62.5000             \n",
      "  1216     0       800     1/111807       0% 0.984825               65.6250             \n",
      "  1340     0       900     1/111807       0% 0.923243               62.5000             \n",
      "  1808     0      1000     1/111807       0% 0.830347 0.881832      56.2500      60.5880\n",
      "  1951     0      1100     1/111807       0% 0.783452               68.7500             \n",
      "  2096     0      1200     1/111807       0% 1.243217               31.2500             \n",
      "  2261     0      1300     1/111807       0% 1.035770               46.8750             \n",
      "  2417     0      1400     1/111807       0% 0.836367               59.3750             \n",
      "  2957     0      1500     1/111807       0% 0.906802 0.896794      59.3750      60.6772\n",
      "  3169     0      1600     1/111807       0% 0.742997               68.7500             \n",
      "  3384     0      1700     1/111807       0% 0.816575               56.2500             \n",
      "  3601     0      1800     1/111807       0% 1.004984               50.0000             \n",
      "  3836     0      1900     1/111807       0% 0.921240               59.3750             \n",
      "  4511     0      2000     1/111807       0% 1.082705 0.880465      53.1250      60.9932\n",
      "  4809     0      2100     1/111807       0% 0.826214               65.6250             \n",
      "  5105     0      2200     1/111807       0% 0.714280               65.6250             \n",
      "  5425     0      2300     1/111807       0% 0.900011               53.1250             \n",
      "  5755     0      2400     1/111807       0% 0.858245               59.3750             \n",
      "  6601     0      2500     1/111807       0% 0.827243 0.881089      71.8750      60.7116\n",
      "  7008     0      2600     1/111807       0% 0.934852               53.1250             \n",
      "  7429     0      2700     1/111807       0% 1.052885               65.6250             \n",
      "  7884     0      2800     1/111807       0% 0.954814               59.3750             \n",
      "  8366     0      2900     1/111807       0% 0.899028               53.1250             \n",
      "  9553     0      3000     1/111807       0% 1.067735 0.862586      53.1250      61.8655\n",
      " 10186     0      3100     1/111807       0% 1.109756               62.5000             \n",
      " 10854     0      3200     1/111807       0% 0.826325               65.6250             \n",
      " 11569     0      3300     1/111807       0% 1.044491               56.2500             \n",
      " 12408     0      3400     1/111807       0% 0.837803               65.6250             \n",
      " 14320     1      3500     1/111807       0% 0.903962 0.857171      62.5000      61.7831\n",
      " 14537     1      3600     1/111807       0% 0.717350               81.2500             \n",
      " 14759     1      3700     1/111807       0% 1.174086               43.7500             \n",
      " 15034     1      3800     1/111807       0% 1.136981               50.0000             \n",
      " 15301     1      3900     1/111807       0% 1.085189               56.2500             \n",
      " 16628     1      4000     1/111807       0% 0.672843 0.861151      68.7500      61.1512\n",
      " 16990     1      4100     1/111807       0% 0.878871               71.8750             \n",
      " 17341     1      4200     1/111807       0% 0.637055               75.0000             \n",
      " 17699     1      4300     1/111807       0% 1.029806               59.3750             \n",
      " 18126     1      4400     1/111807       0% 0.652719               78.1250             \n",
      " 19668     1      4500     1/111807       0% 0.802748 0.847409      62.5000      62.4699\n",
      " 20132     1      4600     1/111807       0% 0.878743               68.7500             \n",
      " 20610     1      4700     1/111807       0% 0.910388               56.2500             \n",
      " 21155     1      4800     1/111807       0% 0.815951               75.0000             \n",
      " 21685     1      4900     1/111807       0% 0.602802               81.2500             \n",
      " 23334     1      5000     1/111807       0% 0.599961 0.866473      75.0000      61.9685\n",
      " 23950     1      5100     1/111807       0% 0.811073               65.6250             \n",
      " 24565     1      5200     1/111807       0% 0.705191               75.0000             \n",
      " 25192     1      5300     1/111807       0% 0.895137               68.7500             \n",
      " 25856     1      5400     1/111807       0% 0.902080               56.2500             \n",
      " 27631     1      5500     1/111807       0% 0.892196 0.865760      71.8750      61.3572\n",
      " 28376     1      5600     1/111807       0% 0.834040               62.5000             \n",
      " 29107     1      5700     1/111807       0% 1.009574               50.0000             \n",
      " 29875     1      5800     1/111807       0% 0.966097               56.2500             \n",
      " 30661     1      5900     1/111807       0% 0.876248               56.2500             \n",
      " 32636     1      6000     1/111807       0% 0.676655 0.881833      75.0000      62.2570\n",
      " 33511     1      6100     1/111807       0% 0.682841               75.0000             \n",
      " 34400     1      6200     1/111807       0% 0.647892               68.7500             \n",
      " 35334     1      6300     1/111807       0% 0.955255               59.3750             \n",
      " 36282     1      6400     1/111807       0% 0.747986               71.8750             \n",
      " 38470     1      6500     1/111807       0% 0.912331 0.872388      50.0000      61.6457\n",
      " 39552     1      6600     1/111807       0% 0.925369               46.8750             \n",
      " 40668     1      6700     1/111807       0% 0.957495               50.0000             \n",
      " 41839     1      6800     1/111807       0% 0.980868               56.2500             \n",
      " 43101     1      6900     1/111807       0% 0.930545               50.0000             \n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3193,216,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Transpose] name: thanos/spinn/transpose/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5285\u001b[0m   \"\"\"\n\u001b[0;32m   5286\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    242\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                     dev_loss, dev_frac_correct = _evaluate_on_dataset(\n\u001b[1;32m--> 244\u001b[1;33m               val_dataset, trainer, use_gpu)\n\u001b[0m\u001b[0;32m    245\u001b[0m                     print(dev_log_template.format(\n\u001b[0;32m    246\u001b[0m                           \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36m_evaluate_on_dataset\u001b[1;34m(val_dataset, trainer, use_gpu)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         sentence_level_outputs = self.sentence_encoder(sentence_embeddings, transitions,\n\u001b[1;32m---> 72\u001b[1;33m                            training = is_training)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m#generate document level embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\SPINN.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, buffers, transitions, training)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;31m# items in a stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     splitted = tf.split(\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_proj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         max_sequence_len * batch_size, axis=0)\n\u001b[0;32m    173\u001b[0m     buffers = [splitted[k:k + max_sequence_len]\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[0;32m   1407\u001b[0m           \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranspose_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(x, perm, name)\u001b[0m\n\u001b[0;32m  10625\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10626\u001b[0m       return transpose_eager_fallback(\n\u001b[1;32m> 10627\u001b[1;33m           x, perm, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m  10628\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10629\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose_eager_fallback\u001b[1;34m(x, perm, name, ctx)\u001b[0m\n\u001b[0;32m  10644\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tperm\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_Tperm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10645\u001b[0m   _result = _execute.execute(b\"Transpose\", 1, inputs=_inputs_flat,\n\u001b[1;32m> 10646\u001b[1;33m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[0;32m  10647\u001b[0m   _execute.record_gradient(\n\u001b[0;32m  10648\u001b[0m       \"Transpose\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3193,216,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Transpose] name: thanos/spinn/transpose/"
     ]
    }
   ],
   "source": [
    "% run train.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "   888     0       500     1/111807       0% 1.091344 1.074856      59.3750      51.8099\n",
      "  1846     0      1000     1/111807       0% 0.799218 0.940371      68.7500      57.8542\n",
      "  3013     0      1500     1/111807       0% 1.007831 0.947673      62.5000      57.8886\n",
      " 33075     0      2000     1/111807       0% 0.891435 0.903693      56.2500      59.1387\n",
      " 35251     0      2500     1/111807       0% 1.020426 0.871471      46.8750      61.4397\n",
      " 38473     0      3000     1/111807       0% 1.077265 0.873243      43.7500      60.7391\n"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    86     0       100     1/111807       0% 0.866206               59.3750             \n",
      "   176     0       200     1/111807       0% 0.892676               65.6250             \n",
      "   277     0       300     1/111807       0% 1.176349               59.3750             \n",
      "   375     0       400     1/111807       0% 0.940301               62.5000             \n",
      "   748     0       500     1/111807       0% 0.927675 0.985549      56.2500      56.3844\n",
      "   871     0       600     1/111807       0% 0.916001               65.6250             \n",
      "   985     0       700     1/111807       0% 0.849378               56.2500             \n",
      "  1100     0       800     1/111807       0% 0.887245               62.5000             \n",
      "  1225     0       900     1/111807       0% 0.779149               59.3750             \n",
      "  1685     0      1000     1/111807       0% 0.741783 0.932501      71.8750      58.6716\n",
      "  1830     0      1100     1/111807       0% 0.868349               71.8750             \n",
      "  1974     0      1200     1/111807       0% 1.346358               31.2500             \n",
      "  2141     0      1300     1/111807       0% 1.026719               50.0000             \n",
      "  2298     0      1400     1/111807       0% 0.896941               53.1250             \n",
      "  2855     0      1500     1/111807       0% 0.871881 0.916661      50.0000      59.2074\n",
      "  3075     0      1600     1/111807       0% 0.846934               65.6250             \n",
      "  3298     0      1700     1/111807       0% 0.978404               50.0000             \n",
      "  3525     0      1800     1/111807       0% 1.107570               37.5000             \n",
      "  3772     0      1900     1/111807       0% 0.946530               65.6250             \n",
      "  4500     0      2000     1/111807       0% 0.971583 0.906913      53.1250      59.8874\n",
      "  4812     0      2100     1/111807       0% 0.820424               65.6250             \n",
      "  5120     0      2200     1/111807       0% 0.691164               68.7500             \n",
      "  5454     0      2300     1/111807       0% 0.949051               71.8750             \n",
      "  5806     0      2400     1/111807       0% 0.912214               71.8750             \n",
      "  6761     0      2500     1/111807       0% 0.948761 0.868375      56.2500      61.4328\n",
      "  7210     0      2600     1/111807       0% 0.811166               56.2500             \n",
      "  7672     0      2700     1/111807       0% 0.900371               59.3750             \n",
      "  8164     0      2800     1/111807       0% 0.854357               68.7500             \n",
      "  8688     0      2900     1/111807       0% 0.850527               59.3750             \n",
      "  9996     0      3000     1/111807       0% 1.036331 0.864694      50.0000      62.0235\n",
      " 10686     0      3100     1/111807       0% 0.952332               56.2500             \n",
      " 11423     0      3200     1/111807       0% 0.744320               62.5000             \n",
      " 12239     0      3300     1/111807       0% 0.815551               53.1250             \n",
      " 13201     0      3400     1/111807       0% 0.814448               68.7500             \n",
      " 15352     1      3500     1/111807       0% 1.056517 0.880073      50.0000      60.7047\n",
      " 15610     1      3600     1/111807       0% 0.684359               68.7500             \n",
      " 15851     1      3700     1/111807       0% 1.060992               46.8750             \n",
      " 16149     1      3800     1/111807       0% 1.083825               50.0000             \n",
      " 16439     1      3900     1/111807       0% 0.899553               68.7500             \n",
      " 17894     1      4000     1/111807       0% 0.644306 0.864116      68.7500      61.6045\n",
      " 18288     1      4100     1/111807       0% 0.655622               71.8750             \n",
      " 18671     1      4200     1/111807       0% 0.662011               68.7500             \n",
      " 19052     1      4300     1/111807       0% 0.878284               62.5000             \n",
      " 19512     1      4400     1/111807       0% 0.761895               71.8750             \n",
      " 21204     1      4500     1/111807       0% 0.735222 0.896537      68.7500      60.3819\n",
      " 21701     1      4600     1/111807       0% 0.888923               59.3750             \n",
      " 22218     1      4700     1/111807       0% 0.914523               62.5000             \n",
      " 22806     1      4800     1/111807       0% 0.741572               75.0000             \n",
      " 23379     1      4900     1/111807       0% 0.688141               75.0000             \n",
      " 25168     1      5000     1/111807       0% 0.625629 0.854318      75.0000      62.4013\n",
      " 25840     1      5100     1/111807       0% 0.608777               78.1250             \n",
      " 26511     1      5200     1/111807       0% 0.635798               75.0000             \n",
      " 27196     1      5300     1/111807       0% 0.910070               62.5000             \n",
      " 27923     1      5400     1/111807       0% 0.718722               75.0000             \n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3193,216,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Transpose] name: thanos/spinn/transpose/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meager_run\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m   5285\u001b[0m   \"\"\"\n\u001b[0;32m   5286\u001b[0m   \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mtrain_or_infer_spinn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mtrain_or_infer_spinn\u001b[1;34m(vocab, trans, params, train_dataset, val_dataset, model_dir, embeddings_matrix)\u001b[0m\n\u001b[0;32m    242\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                     dev_loss, dev_frac_correct = _evaluate_on_dataset(\n\u001b[1;32m--> 244\u001b[1;33m               val_dataset, trainer, use_gpu)\n\u001b[0m\u001b[0;32m    245\u001b[0m                     print(dev_log_template.format(\n\u001b[0;32m    246\u001b[0m                           \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36m_evaluate_on_dataset\u001b[1;34m(val_dataset, trainer, use_gpu)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\model_fn.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         sentence_level_outputs = self.sentence_encoder(sentence_embeddings, transitions,\n\u001b[1;32m---> 72\u001b[1;33m                            training = is_training)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m#generate document level embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mE:\\Thanos\\treehanv3_oneGRU\\model\\SPINN.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, buffers, transitions, training)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;31m# items in a stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     splitted = tf.split(\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_proj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         max_sequence_len * batch_size, axis=0)\n\u001b[0;32m    173\u001b[0m     buffers = [splitted[k:k + max_sequence_len]\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[0;32m   1407\u001b[0m           \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranspose_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(x, perm, name)\u001b[0m\n\u001b[0;32m  10625\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10626\u001b[0m       return transpose_eager_fallback(\n\u001b[1;32m> 10627\u001b[1;33m           x, perm, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m  10628\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10629\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose_eager_fallback\u001b[1;34m(x, perm, name, ctx)\u001b[0m\n\u001b[0;32m  10644\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tperm\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_Tperm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10645\u001b[0m   _result = _execute.execute(b\"Transpose\", 1, inputs=_inputs_flat,\n\u001b[1;32m> 10646\u001b[1;33m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[0;32m  10647\u001b[0m   _execute.record_gradient(\n\u001b[0;32m  10648\u001b[0m       \"Transpose\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda2\\envs\\tf_1.1\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3193,216,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Transpose] name: thanos/spinn/transpose/"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    80     0       100     1/111807       0% 1.155587               34.3750             \n",
      "   167     0       200     1/111807       0% 0.980518               56.2500             \n",
      "   261     0       300     1/111807       0% 1.140060               43.7500             \n",
      "   350     0       400     1/111807       0% 1.196432               37.5000             \n",
      "   710     0       500     1/111807       0% 1.097714 1.087568      56.2500      51.0475\n",
      "   823     0       600     1/111807       0% 1.087528               40.6250             \n",
      "   941     0       700     1/111807       0% 1.102964               50.0000             \n",
      "  1046     0       800     1/111807       0% 0.970306               59.3750             \n",
      "  1171     0       900     1/111807       0% 1.032152               50.0000             \n",
      "  1622     0      1000     1/111807       0% 0.785215 0.936601      68.7500      58.2045\n",
      "  1754     0      1100     1/111807       0% 0.859095               71.8750             \n",
      "  1886     0      1200     1/111807       0% 1.197808               28.1250             \n",
      "  2042     0      1300     1/111807       0% 0.917507               50.0000             \n",
      "  2191     0      1400     1/111807       0% 1.089896               43.7500             \n",
      "  2709     0      1500     1/111807       0% 0.974309 0.934891      56.2500      58.6167\n",
      "  2902     0      1600     1/111807       0% 0.865121               62.5000             \n",
      "  3097     0      1700     1/111807       0% 0.917335               59.3750             \n",
      "  3297     0      1800     1/111807       0% 1.248319               40.6250             \n",
      "  3513     0      1900     1/111807       0% 0.950966               59.3750             \n",
      "  4166     0      2000     1/111807       0% 0.895541 0.905020      59.3750      59.3104\n",
      "  4443     0      2100     1/111807       0% 0.779809               78.1250             \n",
      "  4715     0      2200     1/111807       0% 0.607205               78.1250             \n",
      "  5010     0      2300     1/111807       0% 0.876547               68.7500             \n",
      "  5323     0      2400     1/111807       0% 0.849964               65.6250             \n",
      "  6209     0      2500     1/111807       0% 1.020779 0.868015      43.7500      61.2542\n",
      "  6640     0      2600     1/111807       0% 0.772449               68.7500             \n",
      "  7119     0      2700     1/111807       0% 1.133811               28.1250             \n",
      "  7600     0      2800     1/111807       0% 0.891948               46.8750             \n",
      "  8114     0      2900     1/111807       0% 0.848573               62.5000             \n",
      "  9405     0      3000     1/111807       0% 1.102160 0.878161      43.7500      60.6360\n",
      " 10055     0      3100     1/111807       0% 0.912446               59.3750             \n",
      " 10787     0      3200     1/111807       0% 0.896023               53.1250             \n",
      " 23531     0      3300     1/111807       0% 0.826737               56.2500             \n"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n",
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    91     0       100     1/111807       0% 1.157008               37.5000             \n",
      "   180     0       200     1/111807       0% 1.051083               59.3750             \n",
      "   282     0       300     1/111807       0% 1.177140               46.8750             \n",
      "   372     0       400     1/111807       0% 1.202881               46.8750             \n",
      "   731     0       500     1/111807       0% 1.086643 1.064560      50.0000      52.4967\n",
      "   844     0       600     1/111807       0% 1.042221               40.6250             \n",
      "   950     0       700     1/111807       0% 0.988891               56.2500             \n",
      "  1054     0       800     1/111807       0% 0.953301               56.2500             \n",
      "  1170     0       900     1/111807       0% 0.919678               56.2500             \n",
      "  1616     0      1000     1/111807       0% 0.799721 0.945662      65.6250      57.5864\n",
      "  1748     0      1100     1/111807       0% 0.870540               65.6250             \n",
      "  1878     0      1200     1/111807       0% 1.168946               37.5000             \n",
      "  2028     0      1300     1/111807       0% 0.952508               50.0000             \n",
      "  2170     0      1400     1/111807       0% 0.998779               46.8750             \n",
      "  2673     0      1500     1/111807       0% 0.999527 0.929096      56.2500      58.6098\n",
      "  2866     0      1600     1/111807       0% 0.871225               68.7500             \n",
      "  3060     0      1700     1/111807       0% 0.859987               65.6250             \n",
      "  3259     0      1800     1/111807       0% 1.203587               43.7500             \n",
      "  3475     0      1900     1/111807       0% 0.963325               59.3750             \n",
      "  4119     0      2000     1/111807       0% 0.888632 0.894321      56.2500      60.2239\n",
      "  4402     0      2100     1/111807       0% 0.768276               71.8750             \n",
      "  4680     0      2200     1/111807       0% 0.664979               78.1250             \n",
      "  4976     0      2300     1/111807       0% 0.850163               68.7500             \n",
      "  5285     0      2400     1/111807       0% 0.865828               62.5000             \n",
      "  6456     0      2500     1/111807       0% 0.957193 0.869435      56.2500      61.5152\n",
      "  7177     0      2600     1/111807       0% 0.847919               62.5000             \n",
      " 11736     0      2700     1/111807       0% 1.024554               28.1250             \n",
      " 12193     0      2800     1/111807       0% 0.863651               53.1250             \n"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the datasets...\n",
      "- done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting training for 15 epoch(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    94     0       100     1/111807       0% 0.869059               56.2500             \n",
      "   197     0       200     1/111807       0% 1.006445               59.3750             \n",
      "   308     0       300     1/111807       0% 0.970205               62.5000             \n",
      "   408     0       400     1/111807       0% 0.980999               59.3750             \n",
      "   795     0       500     1/111807       0% 0.836526 0.958806      65.6250      58.2801\n",
      "   926     0       600     1/111807       0% 0.855370               56.2500             \n",
      "  1042     0       700     1/111807       0% 0.985331               62.5000             \n",
      "  1152     0       800     1/111807       0% 0.898901               59.3750             \n",
      "  1272     0       900     1/111807       0% 0.938756               50.0000             \n",
      "  1737     0      1000     1/111807       0% 0.766877 0.901935      65.6250      59.8118\n",
      "  1878     0      1100     1/111807       0% 0.736747               71.8750             \n",
      "  2017     0      1200     1/111807       0% 1.213542               25.0000             \n",
      "  2179     0      1300     1/111807       0% 0.978596               53.1250             \n",
      "  2332     0      1400     1/111807       0% 0.834755               56.2500             \n",
      "  2858     0      1500     1/111807       0% 0.911806 0.923698      59.3750      59.0631\n",
      "  3066     0      1600     1/111807       0% 0.833621               71.8750             \n",
      "  3278     0      1700     1/111807       0% 0.789376               68.7500             \n",
      "  3494     0      1800     1/111807       0% 0.984065               50.0000             \n",
      "  3727     0      1900     1/111807       0% 0.919303               53.1250             \n",
      "  4412     0      2000     1/111807       0% 0.963337 0.879921      56.2500      60.8627\n",
      "  4708     0      2100     1/111807       0% 0.798129               68.7500             \n",
      "  5000     0      2200     1/111807       0% 0.707819               62.5000             \n",
      "  5313     0      2300     1/111807       0% 0.885801               56.2500             \n",
      "  5637     0      2400     1/111807       0% 0.916806               53.1250             \n",
      "  6509     0      2500     1/111807       0% 0.877322 0.865946      71.8750      61.7556\n",
      "  6930     0      2600     1/111807       0% 0.886149               56.2500             \n",
      "  7363     0      2700     1/111807       0% 0.960184               59.3750             \n",
      "  7829     0      2800     1/111807       0% 0.884953               62.5000             \n",
      "  8331     0      2900     1/111807       0% 0.892861               56.2500             \n",
      " 36778     0      3000     1/111807       0% 0.999682 0.864902      50.0000      61.7281\n",
      " 37963     0      3100     1/111807       0% 1.052862               59.3750             \n",
      " 39301     0      3200     1/111807       0% 0.742325               68.7500             \n",
      " 40758     0      3300     1/111807       0% 0.978726               53.1250             \n",
      " 42442     0      3400     1/111807       0% 0.859727               65.6250             \n",
      " 46305     1      3500     1/111807       0% 1.091828 0.884110      50.0000      60.3544\n",
      " 47799     1      3600     1/111807       0% 0.670284               71.8750             \n",
      " 48066     1      3700     1/111807       0% 1.019751               46.8750             \n",
      " 48365     1      3800     1/111807       0% 0.992396               50.0000             \n",
      " 48645     1      3900     1/111807       0% 0.995396               62.5000             \n",
      " 50116     1      4000     1/111807       0% 0.709285 0.861712      68.7500      61.4328\n",
      " 50527     1      4100     1/111807       0% 0.815371               71.8750             \n",
      " 50910     1      4200     1/111807       0% 0.614593               68.7500             \n",
      " 51288     1      4300     1/111807       0% 0.990678               59.3750             \n",
      " 51746     1      4400     1/111807       0% 0.641247               78.1250             \n",
      " 86048     1      4500     1/111807       0% 0.747966 0.857032      68.7500      61.7762\n",
      " 86614     1      4600     1/111807       0% 0.846967               62.5000             \n",
      " 87119     1      4700     1/111807       0% 0.834222               62.5000             \n",
      " 87731     1      4800     1/111807       0% 0.696050               75.0000             \n",
      " 88349     1      4900     1/111807       0% 0.658588               71.8750             \n",
      " 90177     1      5000     1/111807       0% 0.486294 0.882622      78.1250      61.4671\n",
      " 90843     1      5100     1/111807       0% 0.630462               78.1250             \n",
      " 91489     1      5200     1/111807       0% 0.748506               71.8750             \n",
      " 92148     1      5300     1/111807       0% 0.819580               71.8750             \n",
      " 92844     1      5400     1/111807       0% 0.784814               65.6250             \n",
      " 94790     1      5500     1/111807       0% 0.900973 0.851587      68.7500      61.8518\n",
      " 95576     1      5600     1/111807       0% 0.763126               68.7500             \n",
      " 96340     1      5700     1/111807       0% 0.953153               46.8750             \n",
      " 97201     1      5800     1/111807       0% 0.917774               56.2500             \n",
      " 98076     1      5900     1/111807       0% 0.806209               53.1250             \n",
      "100150     1      6000     1/111807       0% 0.639645 0.856692      68.7500      62.9164\n",
      "101043     1      6100     1/111807       0% 0.600839               62.5000             \n",
      "101955     1      6200     1/111807       0% 0.657071               68.7500             \n",
      "102910     1      6300     1/111807       0% 0.890833               62.5000             \n",
      "103898     1      6400     1/111807       0% 0.716311               65.6250             \n",
      "106174     1      6500     1/111807       0% 0.918891 0.875444      50.0000      61.6457\n",
      "107289     1      6600     1/111807       0% 0.874561               50.0000             \n",
      "108431     1      6700     1/111807       0% 0.918518               53.1250             \n",
      "109634     1      6800     1/111807       0% 0.843194               62.5000             \n",
      "110929     1      6900     1/111807       0% 0.880679               65.6250             \n",
      "113304     2      7000     1/111807       0% 0.479673 0.920847      78.1250      59.4546\n",
      "113559     2      7100     1/111807       0% 0.936146               71.8750             \n",
      "113818     2      7200     1/111807       0% 0.632037               78.1250             \n",
      "114137     2      7300     1/111807       0% 0.779213               62.5000             \n",
      "114450     2      7400     1/111807       0% 0.640675               65.6250             \n",
      "116027     2      7500     1/111807       0% 0.853216 0.860957      56.2500      61.5702\n",
      "116450     2      7600     1/111807       0% 0.895280               62.5000             \n",
      "116861     2      7700     1/111807       0% 0.672496               81.2500             \n",
      "117271     2      7800     1/111807       0% 0.960242               59.3750             \n",
      "117775     2      7900     1/111807       0% 0.652866               65.6250             \n",
      "119562     2      8000     1/111807       0% 0.506308 0.861278      71.8750      61.9067\n",
      "120101     2      8100     1/111807       0% 0.631752               75.0000             \n",
      "120671     2      8200     1/111807       0% 0.737248               62.5000             \n",
      "121308     2      8300     1/111807       0% 0.845287               68.7500             \n",
      "121941     2      8400     1/111807       0% 0.703442               65.6250             \n",
      "123884     2      8500     1/111807       0% 0.645730 0.899138      68.7500      61.2748\n",
      "124596     2      8600     1/111807       0% 0.571556               71.8750             \n",
      "125322     2      8700     1/111807       0% 0.812777               71.8750             \n",
      "126056     2      8800     1/111807       0% 0.671462               71.8750             \n",
      "126828     2      8900     1/111807       0% 0.828814               62.5000             \n",
      "129292     2      9000     1/111807       0% 0.867587 0.885373      53.1250      60.5536\n",
      "130382     2      9100     1/111807       0% 0.720979               78.1250             \n",
      "131982     2      9200     1/111807       0% 0.868992               65.6250             \n",
      "133623     2      9300     1/111807       0% 0.585759               68.7500             \n",
      "135355     2      9400     1/111807       0% 0.590952               78.1250             \n",
      "138968     2      9500     1/111807       0% 0.558205 0.874097      81.2500      62.4081\n",
      "140018     2      9600     1/111807       0% 0.792991               75.0000             \n",
      "141062     2      9700     1/111807       0% 0.863124               65.6250             \n",
      "142139     2      9800     1/111807       0% 0.889863               65.6250             \n",
      "143230     2      9900     1/111807       0% 0.804114               59.3750             \n",
      "145757     2     10000     1/111807       0% 0.831607 0.880321      65.6250      62.2570\n",
      "147017     2     10100     1/111807       0% 0.638226               71.8750             \n",
      "148283     2     10200     1/111807       0% 0.679891               75.0000             \n",
      "149623     2     10300     1/111807       0% 0.578976               84.3750             \n",
      "151048     2     10400     1/111807       0% 0.619804               78.1250             \n",
      "153625     3     10500     1/111807       0% 1.180534 0.908566      56.2500      60.8352\n",
      "153913     3     10600     1/111807       0% 0.744211               56.2500             \n",
      "154229     3     10700     1/111807       0% 0.832984               59.3750             \n",
      "154597     3     10800     1/111807       0% 0.762476               56.2500             \n",
      "154960     3     10900     1/111807       0% 0.635986               68.7500             \n",
      "156781     3     11000     1/111807       0% 0.677261 0.889945      68.7500      60.8696\n",
      "157276     3     11100     1/111807       0% 0.763634               65.6250             \n",
      "157773     3     11200     1/111807       0% 0.596933               75.0000             \n",
      "158252     3     11300     1/111807       0% 0.706838               75.0000             \n",
      "158832     3     11400     1/111807       0% 0.487302               81.2500             \n",
      "160893     3     11500     1/111807       0% 0.836200 0.902042      59.3750      61.7487\n",
      "161550     3     11600     1/111807       0% 0.842201               59.3750             \n",
      "162362     3     11700     1/111807       0% 0.592739               71.8750             \n"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the datasets...\n",
      "- done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting training for 15 epoch(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    88     0       100     1/111807       0% 1.156549               34.3750             \n",
      "   178     0       200     1/111807       0% 0.985415               53.1250             \n",
      "   285     0       300     1/111807       0% 1.144855               46.8750             \n",
      "   400     0       400     1/111807       0% 1.181148               40.6250             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   824     0       500     1/111807       0% 1.049351 1.081435      59.3750      51.6244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- Found new best accuracy, saving in experiments/Yelp_newest/best_weights\n",
      "   945     0       600     1/111807       0% 1.101046               40.6250             \n",
      "  1057     0       700     1/111807       0% 1.100891               46.8750             \n",
      "  1170     0       800     1/111807       0% 0.970129               59.3750             \n",
      "  1290     0       900     1/111807       0% 1.030787               56.2500             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1760     0      1000     1/111807       0% 0.801708 0.942081      68.7500      58.0672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- Found new best accuracy, saving in experiments/Yelp_newest/best_weights\n",
      "  1905     0      1100     1/111807       0% 0.867285               71.8750             \n",
      "  2052     0      1200     1/111807       0% 1.168009               34.3750             \n",
      "  2251     0      1300     1/111807       0% 0.901214               50.0000             \n",
      "  2464     0      1400     1/111807       0% 1.054982               43.7500             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3318     0      1500     1/111807       0% 0.988542 0.932500      62.5000      58.5617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- Found new best accuracy, saving in experiments/Yelp_newest/best_weights\n",
      "  3599     0      1600     1/111807       0% 0.890797               65.6250             \n",
      "  3875     0      1700     1/111807       0% 0.901677               59.3750             \n",
      "  4162     0      1800     1/111807       0% 1.213430               43.7500             \n",
      "  4502     0      1900     1/111807       0% 0.950701               65.6250             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5640     0      2000     1/111807       0% 0.897663 0.904474      56.2500      59.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- Found new best accuracy, saving in experiments/Yelp_newest/best_weights\n",
      "  6084     0      2100     1/111807       0% 0.786714               78.1250             \n",
      "  6533     0      2200     1/111807       0% 0.617177               75.0000             \n",
      "  7029     0      2300     1/111807       0% 0.883101               65.6250             \n",
      "  7582     0      2400     1/111807       0% 0.844887               71.8750             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9291     0      2500     1/111807       0% 1.018830 0.876843      46.8750      61.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- Found new best accuracy, saving in experiments/Yelp_newest/best_weights\n",
      " 10026     0      2600     1/111807       0% 0.747321               71.8750             \n",
      " 10836     0      2700     1/111807       0% 1.122479               37.5000             \n",
      " 11756     0      2800     1/111807       0% 0.889482               56.2500             \n",
      " 12722     0      2900     1/111807       0% 0.874759               59.3750             \n"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the datasets...\n",
      "- done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting training for 15 epoch(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu:0\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    95     0       100   100/111807       0% 0.872671               59.3750             \n",
      "   192     0       200   200/111807       0% 0.966475               65.6250             \n",
      "   299     0       300   300/111807       0% 0.921643               68.7500             \n",
      "   402     0       400   400/111807       0% 0.936557               68.7500             \n",
      "   817     0       500   500/111807       0% 0.847709 0.919962      50.0000      59.0219\n",
      "- Found new best accuracy, saving in experiments/Yelp_newest/best_weights\n",
      "   953     0       600   600/111807       1% 0.879415               53.1250             \n",
      "  1079     0       700   700/111807       1% 1.003002               68.7500             \n",
      "  1202     0       800   800/111807       1% 0.902592               62.5000             \n",
      "  1336     0       900   900/111807       1% 0.881349               50.0000             \n",
      "  1914     0      1000  1000/111807       1% 0.792406 0.871611      53.1250      60.8764\n",
      "- Found new best accuracy, saving in experiments/Yelp_newest/best_weights\n",
      "  2078     0      1100  1100/111807       1% 0.745207               68.7500             \n",
      "  2241     0      1200  1200/111807       1% 1.195226               28.1250             \n",
      "  2426     0      1300  1300/111807       1% 0.981353               50.0000             \n",
      "  2605     0      1400  1400/111807       1% 0.866446               65.6250             \n"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the datasets...\n",
      "- done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings from data\\filtered_glove.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting training for 15 epoch(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "    91     0       100   100/111807       0% 0.763290               59.3750             \n",
      "   190     0       200   200/111807       0% 0.895806               62.5000             \n",
      "   298     0       300   300/111807       0% 0.833491               62.5000             \n",
      "   397     0       400   400/111807       0% 0.768003               62.5000             \n",
      "   858     0       500   500/111807       0% 0.785497 0.935824      68.7500      58.4106\n",
      "- Found new best accuracy, saving in experiments/Yelp_11_04/best_weights\n",
      "   986     0       600   600/111807       1% 0.781858               56.2500             \n",
      "  1105     0       700   700/111807       1% 0.935303               65.6250             \n",
      "  1227     0       800   800/111807       1% 0.853874               59.3750             \n",
      "  1370     0       900   900/111807       1% 0.810819               56.2500             \n",
      "  1953     0      1000  1000/111807       1% 0.699693 0.855515      62.5000      61.6869\n",
      "- Found new best accuracy, saving in experiments/Yelp_11_04/best_weights\n",
      "  2112     0      1100  1100/111807       1% 0.704264               84.3750             \n",
      "  2272     0      1200  1200/111807       1% 1.041697               40.6250             \n",
      "  2453     0      1300  1300/111807       1% 0.917405               56.2500             \n",
      "  2627     0      1400  1400/111807       1% 0.816889               62.5000             \n",
      "  3333     0      1500  1500/111807       1% 0.831011 0.864395      59.3750      61.6869\n",
      "- Found new best accuracy, saving in experiments/Yelp_11_04/best_weights\n",
      "  3584     0      1600  1600/111807       1% 0.661692               75.0000             \n",
      "  3837     0      1700  1700/111807       2% 0.746540               68.7500             \n",
      "  4096     0      1800  1800/111807       2% 0.812116               53.1250             \n",
      "  4380     0      1900  1900/111807       2% 0.796269               53.1250             \n",
      "  9179     0      2000  2000/111807       2% 0.949535 0.854703      62.5000      61.9685\n",
      "- Found new best accuracy, saving in experiments/Yelp_11_04/best_weights\n",
      "  9500     0      2100  2100/111807       2% 0.746839               75.0000             \n",
      "  9790     0      2200  2200/111807       2% 0.644559               71.8750             \n",
      " 10110     0      2300  2300/111807       2% 0.813696               62.5000             \n",
      " 10433     0      2400  2400/111807       2% 0.834702               68.7500             \n",
      " 11469     0      2500  2500/111807       2% 0.679761 0.840134      71.8750      62.2982\n",
      "- Found new best accuracy, saving in experiments/Yelp_11_04/best_weights\n",
      " 11879     0      2600  2600/111807       2% 0.660824               65.6250             \n",
      " 12294     0      2700  2700/111807       2% 0.858189               56.2500             \n",
      " 12785     0      2800  2800/111807       3% 0.754787               59.3750             \n",
      " 13425     0      2900  2900/111807       3% 0.761796               59.3750             \n",
      " 14928     0      3000  3000/111807       3% 0.819566 0.853346      56.2500      62.2570\n",
      " 15585     0      3100  3100/111807       3% 0.919884               65.6250             \n",
      " 16350     0      3200  3200/111807       3% 0.686541               71.8750             \n",
      " 17151     0      3300  3300/111807       3% 0.870589               59.3750             \n",
      " 18118     0      3400  3400/111807       3% 0.674262               75.0000             \n"
     ]
    }
   ],
   "source": [
    "% run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
